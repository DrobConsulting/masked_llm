{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drob7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 1) A discrete and Sigmoid diffusion schedule\n",
    "# ------------------------------------------------------------------------\n",
    "class DiscreteDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Simple linear schedule of alpha_t from t=1..T,\n",
    "    where alpha_t = min_alpha + (max_alpha - min_alpha)*(t/T).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=10, min_alpha=0.1, max_alpha=0.7):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            frac = t / T\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha)*frac\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t-1]\n",
    "\n",
    "class SigmoidDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Sigmoid schedule of alpha_t from t=1..T.\n",
    "\n",
    "    alpha_t = min_alpha + (max_alpha - min_alpha)*sigmoid(k*(frac - 0.5)),\n",
    "    where frac = (t-1)/(T-1).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=30, min_alpha=0.1, max_alpha=0.7, k=12.0):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            # frac in [0..1]\n",
    "            frac = (t - 1) / (T - 1)  \n",
    "            # logistic\n",
    "            s = 1 / (1 + math.exp(-k * (frac - 0.5)))\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha) * s\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t - 1]\n",
    "\n",
    "class OneFlipDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Diffusion schedule where `t` digits are flipped at step `t`.\n",
    "    \"\"\"\n",
    "    def __init__(self, T=50, puzzle_size=81):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            T (int): Number of diffusion steps.\n",
    "            puzzle_size (int): Total number of digits in the puzzle (e.g., 81 for 9x9 Sudoku).\n",
    "        \"\"\"\n",
    "        self.T = T\n",
    "        self.puzzle_size = puzzle_size\n",
    "        self.flip_counts = [min(t, puzzle_size) for t in range(1, T + 1)]  # `t` flips at step `t`\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        \"\"\"\n",
    "        Returns the number of flips to apply at step t.\n",
    "        Args:\n",
    "            t (int): Step index (1-based, i.e., t in [1..T]).\n",
    "        \"\"\"\n",
    "        return self.flip_counts[t - 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 2) Forward noising that respects puzzle givens\n",
    "# ------------------------------------------------------------------------\n",
    "def forward_diffusion_with_puzzle(puzzle, solution, t, schedule, vocab_size, device):\n",
    "    \"\"\"\n",
    "    puzzle:   (batch, 81) with digits in [0..9]. 0 means blank, non-zero means given.\n",
    "    solution: (batch, 81) correct final solution\n",
    "    t:        an integer in [1..T]\n",
    "    schedule: contains alpha_t\n",
    "    returns x_t: partially noised solution (batch, 81)\n",
    "        - givens remain the same as solution's corresponding digit\n",
    "        - blank positions get replaced with random digits w.p. alpha_t\n",
    "    \"\"\"\n",
    "    alpha_t = schedule[t]  # fraction to noise\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Where puzzle is nonzero => givens => do NOT overwrite\n",
    "    givens_mask = (puzzle != 0)\n",
    "\n",
    "    # We'll noise only the positions that are blank in the puzzle\n",
    "    #   i.e. puzzle[i] == 0 => we can noise solution[i].\n",
    "    blank_mask = (puzzle == 0)\n",
    "\n",
    "    # Create random noise from [0..vocab_size-1] for the blank positions\n",
    "    noise = torch.randint(0, vocab_size, solution.shape, device=device)\n",
    "\n",
    "    # Decide which blank positions to replace with noise\n",
    "    replace_mask = (torch.rand_like(solution.float()) < alpha_t) & blank_mask\n",
    "\n",
    "    # x_t: start from the true solution, then replace with noise for some blank cells\n",
    "    x_t = solution.clone()\n",
    "    x_t[replace_mask] = noise[replace_mask]\n",
    "\n",
    "    # givens remain the same as the correct solution digit at that position\n",
    "    # (actually, this is already the default if puzzle != 0, but we do not overwrite them)\n",
    "    # so x_t[givens_mask] = solution[givens_mask] # if you want to be explicit\n",
    "\n",
    "    return x_t\n",
    "\n",
    "def forward_diffusion_mixed(\n",
    "    puzzle,\n",
    "    x_prev,\n",
    "    t,\n",
    "    schedule,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    zero_bias=0.8,\n",
    "    bias_increment=1.3\n",
    "):\n",
    "    \"\"\"\n",
    "    Markov forward step from x_{t-1} to x_t by flipping `schedule[t]` digits, \n",
    "    with a bias toward flipping to zero, while respecting puzzle givens.\n",
    "\n",
    "    Args:\n",
    "        puzzle: (batch, 81) Original puzzle digits [0..9], 0 means blank, non-zero means given.\n",
    "        x_prev: (batch, 81) The noised state from the previous step (x_{t-1}).\n",
    "        t:      The current step index in [1..T].\n",
    "        schedule: A diffusion schedule (e.g., OneFlipDiffusionSchedule).\n",
    "        vocab_size: Number of possible digit values, e.g. 10 for digits [0..9].\n",
    "        device: Torch device (\"cuda\" or \"cpu\").\n",
    "        zero_bias: Probability of flipping to zero vs a random digit in blank cells.\n",
    "        bias_increment: Multiplicative factor to increase zero_bias each time we flip to a non-zero digit.\n",
    "    \n",
    "    Returns:\n",
    "        x_t: (batch, 81) The new noised state (x_{t}) after flipping up to `schedule[t]` digits.\n",
    "    \"\"\"\n",
    "    puzzle = puzzle.to(device)\n",
    "    x_prev = x_prev.to(device)\n",
    "\n",
    "    # Number of flips determined by the schedule\n",
    "    num_flips = int(schedule[t])\n",
    "    batch_size, puzzle_size = x_prev.shape\n",
    "    \n",
    "    # Start x_t from x_{t-1}\n",
    "    x_t = x_prev.clone()\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # Randomly select positions to flip\n",
    "        flip_indices = torch.randperm(puzzle_size, device=device)[:num_flips]\n",
    "\n",
    "        current_zero_bias = zero_bias  # Probability of flipping to zero\n",
    "\n",
    "        for idx in flip_indices:\n",
    "            if puzzle[b, idx] != 0:\n",
    "                # Given digits: flip very rarely (e.g., 1% chance)\n",
    "                if random.random() > 0.99:\n",
    "                    x_t[b, idx] = random.randint(1, vocab_size - 1)\n",
    "            else:\n",
    "                # Blank cells: flip to zero or random digit\n",
    "                if random.random() < current_zero_bias:\n",
    "                    x_t[b, idx] = 0\n",
    "                else:\n",
    "                    x_t[b, idx] = random.randint(1, vocab_size - 1)\n",
    "                    # Increase zero_bias after flipping to a nonzero digit\n",
    "                    current_zero_bias = min(1.0, current_zero_bias * bias_increment)\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_forward_diffusion_path(puzzle, solution, schedule, vocab_size, device):\n",
    "    \"\"\"\n",
    "    Generate the entire forward-diffusion chain:\n",
    "       x_0, x_1, ..., x_T\n",
    "    storing each x_t so that we can sample them consistently.\n",
    "\n",
    "    puzzle, solution: (batch, 81)\n",
    "    schedule: (e.g., OneFlipDiffusionSchedule)\n",
    "    vocab_size: e.g. 10\n",
    "    device: 'cuda' or 'cpu'\n",
    "\n",
    "    Returns: A list [x_0, x_1, ..., x_T], each of shape (batch, 81)\n",
    "    \"\"\"\n",
    "    # x_0 = the clean solution (we assume x_0 is solution)\n",
    "    # puzzle is used by forward_diffusion_mixed to avoid flipping givens.\n",
    "\n",
    "    # Make sure they're on the right device\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    x_current = solution.clone()  # start from x_0 = solution\n",
    "    path = [x_current]            # store x_0 in the path\n",
    "\n",
    "    for step in range(1, schedule.T + 1):\n",
    "        # x_step = forward_diffusion_mixed(...) at time = step\n",
    "        # This flips schedule[step] positions in x_current,\n",
    "        # but also respects puzzle givens.\n",
    "        x_next = forward_diffusion_mixed(\n",
    "            puzzle,\n",
    "            x_current,      # note: we use x_current here, not 'solution'\n",
    "            step,\n",
    "            schedule,\n",
    "            vocab_size,\n",
    "            device\n",
    "        )\n",
    "        path.append(x_next)\n",
    "        x_current = x_next\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3) The model sees puzzle+partially noised solution as input\n",
    "# ------------------------------------------------------------------------\n",
    "class PuzzleDenoiser(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_T=40):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Standard embeddings\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 1) Time embedding for t in [1..max_T]\n",
    "        self.time_embedding = nn.Embedding(max_T + 1, embed_dim)\n",
    "        \n",
    "        # Positional embedding for puzzle+solution sequence (learned initialization)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, 162, embed_dim))\n",
    "        nn.init.normal_(self.pos_embedding, mean=0.0, std=0.02)  # Custom initialization\n",
    "        \n",
    "        # Layer norm after positional embeddings\n",
    "        self.post_pos_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, puzzle, x_t, t):\n",
    "        \"\"\"\n",
    "        puzzle, x_t: (batch, 81)\n",
    "        t: (batch,) integer steps in [1..max_T], describing which noising step\n",
    "        \"\"\"\n",
    "        batch_size = puzzle.size(0)\n",
    "        \n",
    "        # Concatenate [puzzle || x_t] => shape (batch, 162)\n",
    "        inp = torch.cat([puzzle, x_t], dim=1)  # (batch, 162)\n",
    "        \n",
    "        # Token embeddings for puzzle + x_t\n",
    "        emb = self.embedding(inp)  # => (batch, 162, embed_dim)\n",
    "        \n",
    "        # 2) Time embedding => Broadcast time embedding across all tokens\n",
    "        t_emb = self.time_embedding(t).unsqueeze(1)  # (batch, 1, embed_dim)\n",
    "        t_broadcast = t_emb.expand(-1, 162, -1)  # Broadcast to match sequence length\n",
    "        emb = emb + t_broadcast\n",
    "        \n",
    "        # 3) Add positional embeddings\n",
    "        cat_emb = emb + self.pos_embedding[:, :162, :]  # Slice positional embeddings to match sequence length\n",
    "        \n",
    "        # Apply layer normalization after positional embeddings\n",
    "        cat_emb = self.post_pos_norm(cat_emb)\n",
    "        \n",
    "        # Pass through Transformer\n",
    "        enc_out = self.encoder(cat_emb)  # => (batch, 162, embed_dim)\n",
    "        \n",
    "        # Apply LayerNorm after Transformer (optional)\n",
    "        enc_out = self.post_pos_norm(enc_out)\n",
    "        \n",
    "        # Output layer => (batch, 162, vocab_size)\n",
    "        logits = self.output_layer(enc_out)\n",
    "        \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4) Diffusion train step\n",
    "# ------------------------------------------------------------------------\n",
    "def compute_subgoal_weights(puzzle, solution, vocab_size=10):\n",
    "    \"\"\"\n",
    "    Computes a difficulty-based weight for each cell in the puzzle:\n",
    "      - If puzzle[i] != 0, it's a given => typically weight = 0 or minimal (since it's known).\n",
    "      - If puzzle[i] == 0, compute how many digits (1..9) are valid in that cell\n",
    "        given Sudoku constraints. The more valid candidates => the harder the subgoal => higher weight.\n",
    "\n",
    "    Returns:\n",
    "        weights: A tensor of shape (batch, 81) with floating-point weights.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = puzzle.size(0)\n",
    "    weights = torch.zeros_like(solution, dtype=torch.float32)\n",
    "\n",
    "    # We'll iterate over each puzzle in the batch\n",
    "    for b in range(batch_size):\n",
    "        # puzzle[b]: shape (81,)\n",
    "        # solution[b]: shape (81,)\n",
    "\n",
    "        # Convert puzzle[b] into a 9x9 grid for easier row/col/box indexing\n",
    "        puzzle_grid = puzzle[b].view(9, 9).cpu().numpy()  # shape (9,9), on CPU\n",
    "        # We'll also want to compute constraints for each row, col, box\n",
    "        # but let's do it cell-by-cell.\n",
    "\n",
    "        for idx in range(81):\n",
    "            r = idx // 9  # row\n",
    "            c = idx % 9   # column\n",
    "\n",
    "            if puzzle_grid[r, c] != 0:\n",
    "                # It's a given => we can optionally set weight to 0 or a small value\n",
    "                weights[b, idx] = 0.0\n",
    "            else:\n",
    "                # It's blank => compute how many valid digits remain\n",
    "                row_vals = set(puzzle_grid[r, :].tolist())\n",
    "                col_vals = set(puzzle_grid[:, c].tolist())\n",
    "\n",
    "                # Identify which 3x3 box (by top-left corner)\n",
    "                box_row = (r // 3) * 3\n",
    "                box_col = (c // 3) * 3\n",
    "                box_vals = set(\n",
    "                    puzzle_grid[box_row:box_row+3, box_col:box_col+3].reshape(-1).tolist()\n",
    "                )\n",
    "\n",
    "                # Givens can be 1..9, ignoring 0 (blank)\n",
    "                used_vals = (row_vals | col_vals | box_vals) - {0}\n",
    "                # valid digits are those in [1..9] not in used_vals\n",
    "                all_digits = set(range(1, vocab_size))  # {1,2,...,9} if vocab=10\n",
    "                valid_candidates = all_digits - used_vals\n",
    "\n",
    "                num_candidates = len(valid_candidates)\n",
    "\n",
    "                # Weight logic:\n",
    "                # e.g., let weight = num_candidates\n",
    "                # or weight = 1 + num_candidates, or scale by some factor\n",
    "                # The bigger the number of candidates => the bigger the weight\n",
    "                weights[b, idx] = float(num_candidates)\n",
    "\n",
    "    # Optionally normalize weights per puzzle\n",
    "    weights = weights / (weights.max(dim=1, keepdim=True)[0].clamp(min=1.0) + 1e-8)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def diffusion_train_step(\n",
    "    model,\n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    optimizer,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    loss_fn,\n",
    "    scaler  # GradScaler instance for mixed precision\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # 1) Generate the entire chain: [x_0, x_1, ..., x_T]\n",
    "    path = generate_forward_diffusion_path(\n",
    "        puzzle, solution, schedule, vocab_size, device\n",
    "    )\n",
    "    # path[i] is x_i, shape (batch, 81)\n",
    "\n",
    "    # 2) Pick random t in [1..T]\n",
    "    T = schedule.T\n",
    "    t_int = np.random.randint(1, T + 1)\n",
    "    t_tensor = torch.tensor([t_int] * puzzle.size(0), device=device)\n",
    "    \n",
    "    # x_t and x_{t-1} from the chain\n",
    "    x_t = path[t_int]\n",
    "    x_t_minus_1 = path[t_int - 1]\n",
    "\n",
    "    # 3) Forward pass\n",
    "    with torch.cuda.amp.autocast():  # Enable mixed precision\n",
    "        logits = model(puzzle, x_t, t_tensor)  # => (batch, 162, vocab_size)\n",
    "\n",
    "        # puzzle is shape (batch, 81)\n",
    "        # x_t is shape (batch, 81)\n",
    "        # so logits has shape (batch, 162, vocab_size)\n",
    "        logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "        # 4) CE loss with target = x_{t-1}\n",
    "        ce_loss = loss_fn(\n",
    "            logits_solution_part.reshape(-1, vocab_size),\n",
    "            x_t_minus_1.reshape(-1)\n",
    "        )\n",
    "\n",
    "    # 5) Scale loss and backprop with GradScaler\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(ce_loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    return ce_loss  # Return tensor without calling .item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5) Validation step\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def diffusion_eval_step(\n",
    "    model, \n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a forward pass during evaluation with time conditioning.\n",
    "\n",
    "    Args:\n",
    "        model: The PuzzleDenoiser model with time conditioning.\n",
    "        puzzle: Tensor of shape (batch, 81) with puzzle digits (0 for blanks).\n",
    "        solution: Tensor of shape (batch, 81) with solution digits.\n",
    "        schedule: The diffusion schedule object containing alphas and T.\n",
    "        loss_fn: The loss function, e.g., nn.CrossEntropyLoss().\n",
    "        vocab_size: Size of the vocabulary (digits 0-9 => 10).\n",
    "        device: torch.device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "        loss: The evaluation loss as a float.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # 1. Sample a random diffusion step t for the entire batch\n",
    "    T = schedule.T\n",
    "    t_int = np.random.randint(1, T + 1)  # Sample t in [1, T]\n",
    "    # Create a tensor of shape (batch_size,) filled with t_int\n",
    "    t_tensor = torch.full((puzzle.size(0),), t_int, dtype=torch.long, device=device)\n",
    "\n",
    "    # 2. Create x_t with forward diffusion\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t_int, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    # 3. Forward pass with time conditioning\n",
    "    logits = model(puzzle, x_t, t_tensor)  # shape: (batch, 162, vocab_size)\n",
    "\n",
    "    # 4. Slice out the solution part\n",
    "    logits_solution_part = logits[:, 81:, :]  # Include only solution tokens\n",
    "\n",
    "    # 5. Compute cross-entropy loss\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),  # (batch*81, vocab_size)\n",
    "        solution.reshape(-1)                           # (batch*81,)\n",
    "    )\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 6) Iterative decoding to fill blank cells\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def iterative_decode(model, puzzle, schedule, vocab_size, device):\n",
    "    model.eval()\n",
    "    \n",
    "    puzzle = puzzle.to(device)\n",
    "    batch_size = puzzle.size(0)\n",
    "    T = schedule.T\n",
    "\n",
    "    # Start from fully-random x_T (or partially random)\n",
    "    # e.g. fill blank positions with random digits, keep givens fixed\n",
    "    x_t = puzzle.clone()\n",
    "    blank_mask = (puzzle == 0)\n",
    "    x_t[blank_mask] = torch.randint(\n",
    "        0, vocab_size, \n",
    "        (batch_size, blank_mask.sum(dim=1)[0].item()), # or simply x_t[blank_mask].shape\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    for curr_t in range(T, 0, -1):\n",
    "        t_tensor = torch.full((batch_size,), curr_t, dtype=torch.long, device=device)\n",
    "        \n",
    "        logits = model(puzzle, x_t, t_tensor)\n",
    "        logits_solution_part = logits[:, 81:, :]\n",
    "        pred_x_t_minus_1 = logits_solution_part.argmax(dim=-1)  # (batch, 81)\n",
    "        \n",
    "        # Update only blank cells\n",
    "        x_t[blank_mask] = pred_x_t_minus_1[blank_mask]\n",
    "\n",
    "    return x_t  # hopefully denoised solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_combined(\n",
    "    model, \n",
    "    schedule,\n",
    "    loader,         # DataLoader for validation\n",
    "    device,\n",
    "    loss_fn,\n",
    "    vocab_size=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Validates with:\n",
    "      - Cross-entropy loss (predicting x_{t-1} from x_t)\n",
    "      - Solve rate (iterative decode to x_0)\n",
    "      - Token-level accuracy for filled-in cells\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    solved_count = 0\n",
    "    correct_token_count = 0\n",
    "    total_token_count = 0\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for puzzles, solutions in tqdm(loader, desc=\"Validation\"):\n",
    "            puzzles = puzzles.to(device)\n",
    "            solutions = solutions.to(device)\n",
    "            batch_size = puzzles.size(0)\n",
    "\n",
    "            # 1) Generate entire chain [x_0, x_1, ..., x_T]\n",
    "            #    Here x_0 = solutions, or puzzle + filled blanks, \n",
    "            #    depending on how you handle x_0 in training.\n",
    "            chain = generate_forward_diffusion_path(\n",
    "                puzzle=puzzles,\n",
    "                solution=solutions,   # or x_0 if your approach differs\n",
    "                schedule=schedule,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            # chain[t] => x_t\n",
    "\n",
    "            # 2) Pick random t in [1..T]\n",
    "            t_int = np.random.randint(1, schedule.T + 1)\n",
    "            t_tensor = torch.full((batch_size,), t_int, dtype=torch.long, device=device)\n",
    "\n",
    "            # 3) Retrieve x_t and x_{t-1} from the chain\n",
    "            x_t         = chain[t_int]\n",
    "            x_t_minus_1 = chain[t_int - 1]\n",
    "\n",
    "            # 4) Forward pass\n",
    "            logits = model(puzzles, x_t, t_tensor)  # => (batch, 162, vocab_size)\n",
    "            logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "            # 5) Loss vs x_{t-1}, not the final solution\n",
    "            loss = loss_fn(\n",
    "                logits_solution_part.reshape(-1, vocab_size),\n",
    "                x_t_minus_1.reshape(-1)\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # 6) Iterative decode for solve rate & token accuracy\n",
    "            x_filled = iterative_decode(\n",
    "                model=model,\n",
    "                puzzle=puzzles,   # puzzle givens\n",
    "                schedule=schedule,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 7) Solve rate: how many boards are 100% correct\n",
    "            eq_mask = (x_filled == solutions)  # (batch, 81)\n",
    "            batch_solved = eq_mask.all(dim=1).sum().item()\n",
    "            solved_count += batch_solved\n",
    "\n",
    "            # 8) Token accuracy on masked cells\n",
    "            masked_mask = (puzzles == 0)               # (batch, 81)\n",
    "            correct_masked = eq_mask & masked_mask      # Correct predictions on blank cells\n",
    "            correct_token_count += correct_masked.sum().item()\n",
    "            total_token_count += masked_mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    solve_rate = solved_count / total_samples\n",
    "    token_acc = (correct_token_count / total_token_count) if total_token_count > 0 else 0.0\n",
    "\n",
    "    return avg_loss, solve_rate, token_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 7) Putting it all together: example training loop\n",
    "# ------------------------------------------------------------------------\n",
    "def train_puzzle_diffusion(\n",
    "    X_train, y_train, \n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50,\n",
    "    best_model_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the PuzzleDenoiser model with time-conditioned diffusion.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    schedule = SigmoidDiffusionSchedule(\n",
    "        T=T, \n",
    "        min_alpha=0.02, \n",
    "        max_alpha=0.7,\n",
    "        k=12.0\n",
    "    )\n",
    "\n",
    "    # Handle multi-GPU setup\n",
    "    multi_gpu = torch.cuda.device_count() > 1\n",
    "    if multi_gpu:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    else:\n",
    "        print(\"Using 1 GPU or CPU.\")\n",
    "\n",
    "    # Initialize the model with max_T matching the schedule\n",
    "    model = PuzzleDenoiser(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_heads=num_heads, \n",
    "        num_layers=num_layers,\n",
    "        max_T=T\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if provided (handling DataParallel)\n",
    "    if best_model_path is not None:\n",
    "        state_dict = torch.load(best_model_path, map_location=device)\n",
    "        \n",
    "        if multi_gpu and not list(state_dict.keys())[0].startswith('module.'):\n",
    "            model.load_state_dict(state_dict)\n",
    "            model = nn.DataParallel(model)\n",
    "        elif not multi_gpu and list(state_dict.keys())[0].startswith('module.'):\n",
    "            new_state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            model.load_state_dict(state_dict)\n",
    "            \n",
    "        print(f\"Loaded model from {best_model_path}\")\n",
    "    elif multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    # Add learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Setup data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset   = TensorDataset(X_val,   y_val)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader    = DataLoader(val_dataset,   batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Initial validation before training\n",
    "    if False:\n",
    "        print(\"Running initial validation (Epoch 0):\")\n",
    "        avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "        print(f\"Initial val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Initial solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "        print(f\"Initial token-level accuracy on validation set: {val_token_acc*100:.2f}%\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_puzzle, batch_solution in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "            # Use autocast for mixed precision training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss_val = diffusion_train_step(\n",
    "                    model=model,\n",
    "                    puzzle=batch_puzzle,\n",
    "                    solution=batch_solution,\n",
    "                    schedule=schedule,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    vocab_size=vocab_size,\n",
    "                    device=device,\n",
    "                    scaler=scaler\n",
    "                )\n",
    "            \n",
    "            train_losses.append(loss_val.item())\n",
    "            \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # Validation\n",
    "        avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "        print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"puzzle_diffuser_best.pt\")\n",
    "            print(f\"  [*] Best model saved @ val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return model, schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load sudoku data\n",
    "df = pd.read_csv('./data/sudoku.csv')\n",
    "\n",
    "# Convert strings to tensors\n",
    "def preprocess_sudoku(puzzle_str):\n",
    "    # Convert string to list of integers and then to tensor\n",
    "    return torch.tensor([int(d) for d in puzzle_str], dtype=torch.long)\n",
    "\n",
    "# Convert all puzzles and solutions\n",
    "puzzles = torch.stack([preprocess_sudoku(p) for p in df['quizzes']])\n",
    "solutions = torch.stack([preprocess_sudoku(s) for s in df['solutions']])\n",
    "\n",
    "# Karpathy split (90/5/5)\n",
    "train_size = 0.9\n",
    "val_size = 0.05\n",
    "test_size = 0.05\n",
    "\n",
    "# First split into train and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    puzzles, solutions, train_size=train_size, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into val and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50\n",
    "    #best_model_path=\"puzzle_diffuser_best.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drob7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_31180\\4138713280.py:72: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/14063 [00:00<?, ?it/s]C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_31180\\4138713280.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_31180\\834247071.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "C:\\Users\\drob7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\cuda\\nccl.py:16: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn(\"PyTorch is not compiled with NCCL support\")\n",
      "Epoch 1 [Train]:   1%|â–         | 208/14063 [01:48<1:59:42,  1.93it/s]"
     ]
    }
   ],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=80,\n",
    "    embed_dim=256,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    batch_size=64,\n",
    "    num_epochs=100\n",
    "    #best_model_path=\"puzzle_diffuser_best.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]])\n",
      "Solution: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]])\n",
      "x_t at t=1: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=2: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 6, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=3: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 2, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 0, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=4: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 0, 6, 6, 9, 3, 1, 2, 5, 0, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 0, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=5: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=6: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=7: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=8: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 0, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=9: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 0, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 8, 8, 5, 0, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=10: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 0, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 0, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 0, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 3, 5, 3, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=11: tensor([[1, 4, 2, 3, 8, 9, 0, 7, 5, 9, 0, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 0, 6, 8, 9, 3, 1, 2, 5, 8, 4, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 0, 6, 7, 2, 9, 1, 4, 3, 8, 8, 0, 1, 7, 6, 4, 0, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=12: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 0, 5, 4, 7, 1, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 0, 4, 9, 7, 8, 0, 1, 6, 0, 9, 3, 1, 2, 5, 0, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 0, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=13: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 1, 9, 0, 6, 7, 2, 0, 1, 4, 3, 8, 8, 3, 0, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=14: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 9, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 0, 0, 8, 0, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 0, 9, 0, 4, 3, 8, 8, 3, 1, 7, 6, 0, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=15: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 0, 5, 4, 9, 7, 8, 0, 1, 6, 0, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 0, 7, 0, 0, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=16: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 5, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 4, 0, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 0, 8, 5, 3, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=17: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 0, 5, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 1, 2, 8, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 0, 0, 5, 3, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=18: tensor([[0, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 6, 0, 4, 7, 0, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 0, 2, 0, 0, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 0, 0, 4, 3, 8, 8, 3, 0, 7, 0, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=19: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 6, 5, 4, 7, 1, 0, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 0, 4, 9, 7, 8, 3, 1, 6, 0, 9, 3, 0, 2, 5, 8, 0, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 0, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 0, 4, 5, 9, 2,\n",
      "         4, 0, 7, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=20: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 2, 4, 7, 0, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 0, 5, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 0, 2, 0, 8, 0, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 0, 1, 7, 0, 4, 5, 9, 2,\n",
      "         0, 2, 9, 8, 5, 3, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=21: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 0, 4, 7, 0, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 0, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 0, 0, 7, 0, 4, 0, 9, 2,\n",
      "         0, 2, 5, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=22: tensor([[1, 4, 2, 3, 0, 9, 0, 7, 5, 9, 8, 6, 5, 4, 7, 1, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 0, 2, 5, 8, 4, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 0, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 0, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=23: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 0, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 0, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 0, 9, 3, 0, 0, 0, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 0, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 0, 1, 7, 6, 4, 5, 9, 2,\n",
      "         0, 0, 9, 8, 5, 3, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=24: tensor([[1, 4, 2, 0, 8, 9, 0, 7, 5, 9, 8, 0, 5, 4, 7, 0, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 0, 1, 6, 0, 0, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 0, 5, 6, 7, 0, 7, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         0, 0, 0, 8, 5, 3, 7, 0, 1]], device='cuda:0')\n",
      "x_t at t=25: tensor([[0, 4, 2, 3, 0, 9, 0, 7, 5, 9, 0, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 0, 6, 6, 9, 3, 1, 8, 5, 8, 0, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 5, 6, 7, 2, 0, 0, 4, 3, 8, 8, 3, 0, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=26: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 0, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 0, 6, 6, 0, 3, 1, 2, 5, 8, 4, 8, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 9, 0, 6, 1, 0, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=27: tensor([[1, 4, 2, 3, 8, 9, 0, 7, 5, 9, 8, 6, 0, 4, 7, 1, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 4, 0, 0, 4, 9, 7, 8, 0, 1, 6, 6, 9, 3, 1, 0, 0, 8, 4, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 2, 9, 1, 4, 3, 8, 8, 5, 1, 7, 6, 4, 5, 9, 2,\n",
      "         0, 2, 9, 8, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=28: tensor([[0, 4, 2, 3, 0, 9, 0, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 0, 2, 0, 0, 4, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 2, 9, 5, 6, 7, 0, 9, 0, 4, 3, 8, 8, 0, 0, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=29: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 0, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 4, 0, 2, 5, 4, 9, 7, 8, 0, 1, 6, 6, 0, 3, 0, 2, 0, 8, 0, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 0, 9, 0, 4, 3, 8, 8, 3, 1, 7, 6, 0, 5, 9, 2,\n",
      "         0, 2, 0, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=30: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 2, 5, 4, 7, 1, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 4, 0, 0, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 0, 0, 0, 8, 0, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 0, 9, 0, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=31: tensor([[0, 4, 2, 3, 0, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 0, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 4, 2, 0, 4, 9, 7, 8, 3, 0, 6, 0, 0, 3, 0, 2, 0, 8, 4, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         0, 2, 0, 8, 5, 3, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=32: tensor([[0, 4, 2, 0, 8, 9, 0, 7, 5, 9, 8, 0, 0, 0, 7, 0, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 1, 4, 0, 0, 4, 9, 7, 8, 0, 1, 6, 6, 0, 3, 0, 2, 5, 0, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 3, 3, 8, 8, 0, 1, 7, 6, 0, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 0, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=33: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 0, 0, 4, 7, 1, 0, 3, 3, 9, 5, 6, 1, 0,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 0, 6, 6, 9, 3, 0, 0, 0, 8, 4, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 9, 0, 6, 7, 0, 9, 1, 4, 3, 8, 8, 3, 1, 7, 0, 0, 5, 9, 2,\n",
      "         0, 2, 0, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=34: tensor([[0, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 6, 5, 4, 7, 1, 4, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 0, 4, 9, 7, 8, 3, 0, 6, 6, 0, 3, 0, 0, 5, 8, 0, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 0, 0, 1, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 0, 0]], device='cuda:0')\n",
      "x_t at t=35: tensor([[1, 4, 2, 3, 0, 9, 0, 7, 5, 9, 1, 6, 0, 0, 7, 1, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 0, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 1, 2, 5, 0, 4, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 0, 1, 4, 3, 8, 8, 0, 0, 7, 0, 4, 0, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=36: tensor([[1, 4, 2, 0, 8, 9, 0, 7, 5, 9, 0, 0, 0, 4, 7, 0, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 0, 5, 4, 9, 7, 8, 3, 0, 6, 6, 9, 3, 0, 2, 0, 8, 4, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 0, 6, 7, 2, 0, 5, 4, 3, 8, 8, 0, 1, 7, 0, 0, 5, 9, 2,\n",
      "         4, 2, 9, 0, 5, 3, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=37: tensor([[1, 4, 2, 3, 8, 9, 0, 7, 5, 9, 0, 4, 5, 0, 7, 1, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 0, 9, 3, 0, 2, 0, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 0, 0, 6, 7, 2, 0, 1, 4, 3, 8, 8, 0, 0, 7, 6, 0, 5, 6, 2,\n",
      "         4, 0, 9, 8, 5, 0, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=38: tensor([[0, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 0, 5, 4, 7, 1, 2, 3, 3, 0, 5, 6, 1, 4,\n",
      "         9, 0, 4, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 5, 0, 4, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 5, 6, 7, 0, 9, 1, 4, 3, 8, 8, 3, 1, 7, 0, 4, 0, 9, 2,\n",
      "         0, 2, 0, 0, 5, 0, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=39: tensor([[0, 4, 2, 3, 0, 9, 0, 7, 5, 9, 8, 0, 5, 4, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 4, 2, 2, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 1, 2, 5, 0, 4, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 5, 6, 7, 0, 0, 1, 4, 3, 8, 8, 0, 1, 7, 0, 0, 5, 9, 2,\n",
      "         0, 2, 0, 0, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=40: tensor([[1, 4, 2, 3, 0, 9, 0, 7, 5, 9, 0, 0, 5, 0, 7, 0, 0, 3, 3, 0, 5, 6, 6, 0,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 0, 0, 6, 6, 0, 3, 1, 0, 0, 8, 4, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 3, 1, 7, 0, 0, 0, 9, 2,\n",
      "         4, 2, 9, 0, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=41: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 6, 0, 0, 7, 0, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 0, 6, 6, 0, 3, 1, 2, 5, 8, 0, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 0, 6, 7, 0, 0, 1, 4, 3, 8, 8, 3, 0, 7, 6, 0, 0, 9, 2,\n",
      "         4, 0, 9, 8, 5, 0, 7, 0, 1]], device='cuda:0')\n",
      "x_t at t=42: tensor([[0, 4, 2, 3, 0, 9, 6, 7, 5, 9, 8, 6, 0, 4, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 4, 2, 0, 4, 9, 7, 8, 0, 0, 6, 6, 0, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 0, 5, 6, 7, 0, 9, 1, 4, 3, 8, 8, 0, 0, 7, 6, 0, 5, 9, 2,\n",
      "         4, 2, 9, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=43: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 0, 6, 5, 0, 7, 1, 0, 3, 3, 0, 5, 6, 1, 9,\n",
      "         9, 8, 4, 2, 0, 4, 9, 7, 8, 3, 0, 6, 0, 9, 3, 0, 2, 0, 0, 0, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 0, 6, 7, 0, 9, 1, 4, 3, 8, 8, 3, 0, 7, 0, 0, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=44: tensor([[0, 4, 2, 3, 8, 9, 0, 7, 5, 9, 8, 0, 0, 4, 7, 0, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 0, 4, 0, 0, 4, 9, 7, 8, 3, 0, 6, 0, 0, 3, 0, 0, 5, 0, 4, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 4, 0, 6, 7, 0, 9, 1, 4, 3, 8, 8, 3, 0, 7, 6, 0, 0, 9, 2,\n",
      "         4, 0, 9, 0, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_t at t=45: tensor([[1, 4, 2, 0, 8, 9, 0, 7, 5, 9, 8, 6, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 0, 0, 5, 4, 9, 7, 8, 3, 0, 6, 0, 9, 3, 0, 0, 0, 8, 0, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 3, 0, 7, 6, 0, 5, 9, 2,\n",
      "         0, 2, 7, 8, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=46: tensor([[0, 4, 2, 0, 0, 9, 6, 7, 5, 9, 8, 6, 0, 4, 7, 0, 0, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 0, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 0, 2, 5, 0, 0, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 0, 0, 6, 7, 2, 0, 1, 4, 3, 8, 8, 3, 1, 7, 1, 4, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=47: tensor([[1, 4, 2, 0, 0, 9, 6, 7, 5, 9, 8, 6, 0, 4, 7, 0, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 1, 0, 0, 8, 4, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 5, 6, 7, 0, 9, 0, 4, 3, 8, 8, 0, 0, 7, 6, 0, 0, 9, 2,\n",
      "         0, 2, 0, 8, 5, 3, 7, 0, 1]], device='cuda:0')\n",
      "x_t at t=48: tensor([[0, 4, 2, 0, 0, 9, 6, 7, 5, 9, 8, 0, 0, 0, 7, 1, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 9, 3, 0, 0, 0, 0, 0, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 4, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         0, 2, 9, 0, 5, 3, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=49: tensor([[1, 4, 2, 3, 8, 9, 0, 7, 5, 9, 0, 6, 0, 0, 7, 0, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 5, 4, 9, 7, 8, 0, 1, 6, 6, 0, 3, 0, 2, 0, 8, 0, 7, 0, 1, 8,\n",
      "         4, 3, 6, 2, 0, 0, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 3, 1, 7, 0, 0, 5, 9, 2,\n",
      "         4, 0, 0, 0, 5, 3, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=50: tensor([[1, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 6, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 0, 2, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 1, 2, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 5, 6, 7, 2, 9, 0, 4, 3, 8, 8, 0, 1, 7, 0, 4, 0, 9, 2,\n",
      "         4, 2, 0, 4, 5, 0, 7, 6, 0]], device='cuda:0')\n",
      "x_t at t=51: tensor([[0, 4, 2, 3, 0, 9, 0, 7, 5, 9, 0, 6, 5, 4, 7, 1, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 5, 4, 9, 7, 8, 0, 1, 6, 0, 0, 3, 1, 2, 0, 0, 0, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 9, 3, 6, 7, 0, 0, 1, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=52: tensor([[1, 4, 2, 3, 0, 9, 0, 7, 5, 9, 8, 0, 0, 4, 7, 0, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 0, 0, 0, 4, 9, 7, 8, 0, 1, 6, 6, 0, 3, 1, 0, 0, 8, 4, 0, 0, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 5, 6, 7, 2, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 1, 0, 9, 2,\n",
      "         0, 0, 0, 8, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=53: tensor([[1, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 0, 0, 4, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 4, 0, 0, 4, 9, 7, 8, 3, 0, 6, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 7, 6, 7, 0, 9, 0, 4, 3, 8, 4, 0, 0, 7, 6, 0, 0, 9, 2,\n",
      "         4, 0, 9, 0, 5, 3, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=54: tensor([[1, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 0, 4, 0, 5, 4, 9, 7, 8, 3, 1, 6, 0, 0, 3, 1, 0, 0, 8, 0, 7, 7, 1, 8,\n",
      "         4, 0, 6, 2, 5, 9, 0, 6, 7, 0, 9, 0, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         0, 2, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=55: tensor([[9, 4, 2, 0, 8, 9, 0, 7, 5, 9, 0, 6, 0, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 0, 4, 2, 0, 4, 9, 7, 8, 3, 0, 6, 0, 0, 3, 0, 0, 0, 8, 0, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 2, 9, 0, 4, 3, 8, 8, 3, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=56: tensor([[0, 4, 2, 1, 0, 9, 0, 7, 5, 9, 0, 6, 0, 4, 7, 0, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 0, 0, 5, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 0, 2, 5, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 1, 7, 0, 0, 0, 9, 2,\n",
      "         0, 2, 9, 0, 5, 0, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=57: tensor([[1, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 6, 0, 0, 7, 1, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 3, 1, 6, 0, 0, 3, 0, 0, 0, 8, 0, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 0, 6, 7, 0, 9, 1, 4, 3, 8, 8, 0, 0, 7, 0, 4, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=58: tensor([[1, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 0, 0, 4, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 5, 4, 9, 6, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 8, 4, 0, 7, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 0, 6, 7, 0, 9, 1, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 2, 9, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=59: tensor([[0, 4, 2, 3, 8, 9, 0, 7, 5, 9, 0, 6, 5, 4, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 4, 0, 2, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 3, 6, 2, 0, 9, 0, 6, 7, 2, 0, 0, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=60: tensor([[0, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 8, 4, 0, 0, 4, 9, 7, 8, 0, 8, 6, 0, 9, 3, 0, 2, 0, 8, 4, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 9, 0, 4, 1, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         4, 0, 0, 0, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=61: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 6, 0, 4, 7, 0, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 1, 0, 0, 0, 0, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 5, 0, 5, 6, 7, 2, 0, 1, 4, 3, 8, 8, 0, 1, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 9, 8, 5, 6, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=62: tensor([[1, 4, 2, 3, 0, 9, 6, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 0, 4, 0, 0, 4, 9, 7, 8, 3, 1, 6, 0, 9, 3, 0, 0, 0, 0, 0, 7, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 3, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 8, 5, 4, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=63: tensor([[0, 4, 2, 0, 0, 9, 6, 7, 5, 9, 0, 0, 0, 0, 7, 1, 2, 3, 3, 3, 5, 6, 1, 0,\n",
      "         9, 8, 0, 0, 0, 4, 9, 7, 8, 3, 0, 6, 0, 0, 3, 0, 2, 0, 8, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         4, 0, 9, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=64: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 5, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 2, 0, 8, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 2, 0, 0, 4, 3, 8, 8, 4, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 9, 8, 5, 3, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=65: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 8, 5, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 5, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=66: tensor([[0, 4, 2, 0, 8, 9, 6, 7, 5, 9, 8, 0, 0, 0, 7, 1, 2, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 4, 0, 5, 4, 9, 7, 8, 0, 0, 6, 0, 9, 3, 0, 0, 5, 8, 4, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 6, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=67: tensor([[0, 4, 2, 3, 0, 9, 6, 7, 5, 9, 0, 0, 0, 4, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 4, 0, 5, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 7, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 1]], device='cuda:0')\n",
      "x_t at t=68: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 4, 7, 0, 3, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 0, 0, 5, 4, 9, 7, 8, 0, 0, 6, 6, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 2, 0, 0, 4, 3, 8, 8, 3, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_t at t=69: tensor([[1, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 2, 3, 3, 7, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 6, 0, 3, 0, 0, 5, 0, 4, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 9, 0, 6, 7, 0, 0, 1, 4, 3, 8, 8, 0, 0, 7, 6, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 6, 0]], device='cuda:0')\n",
      "x_t at t=70: tensor([[1, 4, 2, 3, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 3, 0, 6, 0, 9, 3, 1, 0, 0, 0, 0, 0, 7, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 6, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=71: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 3, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 2, 0, 0, 5, 7, 7, 0, 0]], device='cuda:0')\n",
      "x_t at t=72: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 4, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 4, 5, 9, 2,\n",
      "         8, 0, 0, 8, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=73: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 2, 5, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 4, 6, 7, 0, 0, 0, 4, 3, 8, 8, 3, 0, 7, 0, 4, 0, 9, 2,\n",
      "         4, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=74: tensor([[0, 4, 2, 3, 0, 9, 6, 7, 5, 9, 0, 0, 0, 0, 7, 1, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 2, 7, 0, 0, 0, 9, 2,\n",
      "         0, 2, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=75: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 9, 3, 0, 0, 0, 8, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 1, 7, 6, 0, 0, 9, 2,\n",
      "         7, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=76: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 8, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 5, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 5, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 8, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=77: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 6, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 5, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 8, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=78: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 5, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 1, 0, 9, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n",
      "x_t at t=79: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 4, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 2, 0]], device='cuda:0')\n",
      "x_t at t=80: tensor([[0, 4, 2, 9, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2) CREATE THE NEW SCHEDULE\n",
    "#############################################\n",
    "schedule = OneFlipDiffusionSchedule(\n",
    "    T=80\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# 3) PICK A SAMPLE PUZZLE & SOLUTION\n",
    "#############################################\n",
    "sample_puzzle = X_train[0:1]\n",
    "sample_solution = y_train[0:1]\n",
    "\n",
    "print(\"Puzzle:\", sample_puzzle)\n",
    "print(\"Solution:\", sample_solution)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#############################################\n",
    "# 4) SHOW x_1, x_2, ... x_T\n",
    "#############################################\n",
    "vocab_size = 10  # digits 0-9\n",
    "for t in range(1, schedule.T + 1):\n",
    "    x_t = forward_diffusion_mixed(X_train[:1], y_train[:1], t, schedule, vocab_size=10, device=device, bias_increment=1.3)\n",
    "    print(f\"x_t at t={t}:\", x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterative_decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Then to do iterative decoding:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m puzzle_batch \u001b[38;5;241m=\u001b[39m X_val[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# for example\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x_filled \u001b[38;5;241m=\u001b[39m \u001b[43miterative_decode\u001b[49m(\n\u001b[0;32m      5\u001b[0m     model, \n\u001b[0;32m      6\u001b[0m     puzzle\u001b[38;5;241m=\u001b[39mpuzzle_batch, \n\u001b[0;32m      7\u001b[0m     schedule\u001b[38;5;241m=\u001b[39mschedule, \n\u001b[0;32m      8\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPuzzle: \u001b[39m\u001b[38;5;124m\"\u001b[39m, puzzle_batch)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded solution: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x_filled)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iterative_decode' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Then to do iterative decoding:\n",
    "puzzle_batch = X_val[0:2]  # for example\n",
    "x_filled = iterative_decode(\n",
    "    model, \n",
    "    puzzle=puzzle_batch, \n",
    "    schedule=schedule, \n",
    "    vocab_size=10,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Puzzle: \", puzzle_batch)\n",
    "print(\"Decoded solution: \", x_filled)\n",
    "print(\"Original solution: \", y_val[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = measure_sudoku_solve_rate(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val[0:100],\n",
    "    y_val[0:100],\n",
    "    device=device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Solve rate on validation set: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small validation dataset for testing\n",
    "X_val_test = X_val[:1000]\n",
    "y_val_test = y_val[:1000]\n",
    "test_val_loader = DataLoader(\n",
    "    TensorDataset(X_val_test, y_val_test),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run validation\n",
    "avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "    model=model,\n",
    "    schedule=schedule, \n",
    "    loader=test_val_loader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

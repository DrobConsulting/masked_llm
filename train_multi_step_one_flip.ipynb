{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 1) A discrete and Sigmoid diffusion schedule\n",
    "# ------------------------------------------------------------------------\n",
    "class DiscreteDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Simple linear schedule of alpha_t from t=1..T,\n",
    "    where alpha_t = min_alpha + (max_alpha - min_alpha)*(t/T).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=10, min_alpha=0.1, max_alpha=0.7):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            frac = t / T\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha)*frac\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t-1]\n",
    "\n",
    "class SigmoidDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Sigmoid schedule of alpha_t from t=1..T.\n",
    "\n",
    "    alpha_t = min_alpha + (max_alpha - min_alpha)*sigmoid(k*(frac - 0.5)),\n",
    "    where frac = (t-1)/(T-1).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=30, min_alpha=0.1, max_alpha=0.7, k=12.0):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            # frac in [0..1]\n",
    "            frac = (t - 1) / (T - 1)  \n",
    "            # logistic\n",
    "            s = 1 / (1 + math.exp(-k * (frac - 0.5)))\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha) * s\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t - 1]\n",
    "\n",
    "class OneFlipDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Diffusion schedule where `t` digits are flipped at step `t`.\n",
    "    \"\"\"\n",
    "    def __init__(self, T=50, puzzle_size=81):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            T (int): Number of diffusion steps.\n",
    "            puzzle_size (int): Total number of digits in the puzzle (e.g., 81 for 9x9 Sudoku).\n",
    "        \"\"\"\n",
    "        self.T = T\n",
    "        self.puzzle_size = puzzle_size\n",
    "        self.flip_counts = [min(t, puzzle_size) for t in range(1, T + 1)]  # `t` flips at step `t`\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        \"\"\"\n",
    "        Returns the number of flips to apply at step t.\n",
    "        Args:\n",
    "            t (int): Step index (1-based, i.e., t in [1..T]).\n",
    "        \"\"\"\n",
    "        return self.flip_counts[t - 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 2) Forward noising that respects puzzle givens\n",
    "# ------------------------------------------------------------------------\n",
    "def forward_diffusion_with_puzzle(puzzle, solution, t, schedule, vocab_size, device):\n",
    "    \"\"\"\n",
    "    puzzle:   (batch, 81) with digits in [0..9]. 0 means blank, non-zero means given.\n",
    "    solution: (batch, 81) correct final solution\n",
    "    t:        an integer in [1..T]\n",
    "    schedule: contains alpha_t\n",
    "    returns x_t: partially noised solution (batch, 81)\n",
    "        - givens remain the same as solution's corresponding digit\n",
    "        - blank positions get replaced with random digits w.p. alpha_t\n",
    "    \"\"\"\n",
    "    alpha_t = schedule[t]  # fraction to noise\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Where puzzle is nonzero => givens => do NOT overwrite\n",
    "    givens_mask = (puzzle != 0)\n",
    "\n",
    "    # We'll noise only the positions that are blank in the puzzle\n",
    "    #   i.e. puzzle[i] == 0 => we can noise solution[i].\n",
    "    blank_mask = (puzzle == 0)\n",
    "\n",
    "    # Create random noise from [0..vocab_size-1] for the blank positions\n",
    "    noise = torch.randint(0, vocab_size, solution.shape, device=device)\n",
    "\n",
    "    # Decide which blank positions to replace with noise\n",
    "    replace_mask = (torch.rand_like(solution.float()) < alpha_t) & blank_mask\n",
    "\n",
    "    # x_t: start from the true solution, then replace with noise for some blank cells\n",
    "    x_t = solution.clone()\n",
    "    x_t[replace_mask] = noise[replace_mask]\n",
    "\n",
    "    # givens remain the same as the correct solution digit at that position\n",
    "    # (actually, this is already the default if puzzle != 0, but we do not overwrite them)\n",
    "    # so x_t[givens_mask] = solution[givens_mask] # if you want to be explicit\n",
    "\n",
    "    return x_t\n",
    "\n",
    "def forward_diffusion_mixed(puzzle, solution, t, schedule, vocab_size, device, zero_bias=0.8, bias_increment=1.3):\n",
    "    \"\"\"\n",
    "    Hybrid diffusion: flips `t` digits (1-flip pattern) with a bias toward flipping to zeros.\n",
    "    The zero_bias increases multiplicatively after each random flip to limit multiple wrong positions.\n",
    "\n",
    "    Args:\n",
    "        puzzle: (batch, 81) Original puzzle with digits in [0..9], where 0 means blank.\n",
    "        solution: (batch, 81) Correct final solution.\n",
    "        t: Step in the schedule (1..T).\n",
    "        schedule: Diffusion schedule determining the number of flips.\n",
    "        vocab_size: Total number of possible values (e.g., 10 for digits 0-9).\n",
    "        device: Torch device (e.g., \"cuda\").\n",
    "        zero_bias: Initial probability of flipping to zero instead of a random digit.\n",
    "        bias_increment: Multiplicative factor to increase zero_bias (default: 1.2).\n",
    "\n",
    "    Returns:\n",
    "        x_t: Noised solution (batch, 81).\n",
    "    \"\"\"\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Number of flips determined by the schedule (1-flip pattern)\n",
    "    num_flips = int(schedule[t])\n",
    "    batch_size, puzzle_size = solution.shape\n",
    "    x_t = solution.clone()\n",
    "\n",
    "    for b in range(batch_size):\n",
    "        # Select `num_flips` random positions to flip\n",
    "        all_positions = torch.arange(puzzle_size, device=device)\n",
    "        flip_indices = torch.randperm(puzzle_size, device=device)[:num_flips]\n",
    "\n",
    "        current_zero_bias = zero_bias  # Start with the initial zero_bias for this batch\n",
    "\n",
    "        for idx in flip_indices:\n",
    "            if puzzle[b, idx] != 0:\n",
    "                # Given digits: Flip with a small probability\n",
    "                if random.random() > 0.99:  # Flip only 1% of the time\n",
    "                    x_t[b, idx] = random.randint(1, vocab_size - 1)\n",
    "            else:\n",
    "                # Blank cells: Flip with bias toward zero\n",
    "                if random.random() < current_zero_bias:\n",
    "                    x_t[b, idx] = 0  # Flip to zero\n",
    "                else:\n",
    "                    x_t[b, idx] = random.randint(1, vocab_size - 1)  # Flip to random digit\n",
    "                    # Increment the bias multiplicatively\n",
    "                    current_zero_bias = min(1.0, current_zero_bias * bias_increment)\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3) The model sees puzzle+partially noised solution as input\n",
    "# ------------------------------------------------------------------------\n",
    "class PuzzleDenoiser(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, max_T=40):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # Standard embeddings\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        \n",
    "        # 1) Time embedding for t in [1..max_T]\n",
    "        self.time_embedding = nn.Embedding(max_T + 1, embed_dim)\n",
    "        \n",
    "        # Positional embedding for puzzle+solution sequence (learned initialization)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, 163, embed_dim))\n",
    "        nn.init.normal_(self.pos_embedding, mean=0.0, std=0.02)  # Custom initialization\n",
    "        \n",
    "        # Layer norm after positional embeddings\n",
    "        self.post_pos_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, puzzle, x_t, t):\n",
    "        \"\"\"\n",
    "        puzzle, x_t: (batch, 81)\n",
    "        t: (batch,) integer steps in [1..max_T], describing which noising step\n",
    "        \"\"\"\n",
    "        batch_size = puzzle.size(0)\n",
    "        \n",
    "        # Concatenate [puzzle || x_t] => shape (batch, 162)\n",
    "        inp = torch.cat([puzzle, x_t], dim=1)  # (batch, 162)\n",
    "        \n",
    "        # Token embeddings for puzzle + x_t\n",
    "        emb = self.embedding(inp)  # => (batch, 162, embed_dim)\n",
    "        \n",
    "        # 2) Time embedding => Broadcast time embedding across all tokens\n",
    "        t_emb = self.time_embedding(t).unsqueeze(1)  # (batch, 1, embed_dim)\n",
    "        t_broadcast = t_emb.expand(-1, 162, -1)  # Broadcast to match sequence length\n",
    "        emb = emb + t_broadcast\n",
    "        \n",
    "        # 3) Add positional embeddings\n",
    "        cat_emb = emb + self.pos_embedding[:, :162, :]  # Slice positional embeddings to match sequence length\n",
    "        \n",
    "        # Apply layer normalization after positional embeddings\n",
    "        cat_emb = self.post_pos_norm(cat_emb)\n",
    "        \n",
    "        # Pass through Transformer\n",
    "        enc_out = self.encoder(cat_emb)  # => (batch, 162, embed_dim)\n",
    "        \n",
    "        # Apply LayerNorm after Transformer (optional)\n",
    "        enc_out = self.post_pos_norm(enc_out)\n",
    "        \n",
    "        # Output layer => (batch, 162, vocab_size)\n",
    "        logits = self.output_layer(enc_out)\n",
    "        \n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4) Diffusion train step\n",
    "# ------------------------------------------------------------------------\n",
    "def compute_subgoal_weights(puzzle, solution, vocab_size=10):\n",
    "    \"\"\"\n",
    "    Computes a difficulty-based weight for each cell in the puzzle:\n",
    "      - If puzzle[i] != 0, it's a given => typically weight = 0 or minimal (since it's known).\n",
    "      - If puzzle[i] == 0, compute how many digits (1..9) are valid in that cell\n",
    "        given Sudoku constraints. The more valid candidates => the harder the subgoal => higher weight.\n",
    "\n",
    "    Returns:\n",
    "        weights: A tensor of shape (batch, 81) with floating-point weights.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = puzzle.size(0)\n",
    "    weights = torch.zeros_like(solution, dtype=torch.float32)\n",
    "\n",
    "    # We'll iterate over each puzzle in the batch\n",
    "    for b in range(batch_size):\n",
    "        # puzzle[b]: shape (81,)\n",
    "        # solution[b]: shape (81,)\n",
    "\n",
    "        # Convert puzzle[b] into a 9x9 grid for easier row/col/box indexing\n",
    "        puzzle_grid = puzzle[b].view(9, 9).cpu().numpy()  # shape (9,9), on CPU\n",
    "        # We'll also want to compute constraints for each row, col, box\n",
    "        # but let's do it cell-by-cell.\n",
    "\n",
    "        for idx in range(81):\n",
    "            r = idx // 9  # row\n",
    "            c = idx % 9   # column\n",
    "\n",
    "            if puzzle_grid[r, c] != 0:\n",
    "                # It's a given => we can optionally set weight to 0 or a small value\n",
    "                weights[b, idx] = 0.0\n",
    "            else:\n",
    "                # It's blank => compute how many valid digits remain\n",
    "                row_vals = set(puzzle_grid[r, :].tolist())\n",
    "                col_vals = set(puzzle_grid[:, c].tolist())\n",
    "\n",
    "                # Identify which 3x3 box (by top-left corner)\n",
    "                box_row = (r // 3) * 3\n",
    "                box_col = (c // 3) * 3\n",
    "                box_vals = set(\n",
    "                    puzzle_grid[box_row:box_row+3, box_col:box_col+3].reshape(-1).tolist()\n",
    "                )\n",
    "\n",
    "                # Givens can be 1..9, ignoring 0 (blank)\n",
    "                used_vals = (row_vals | col_vals | box_vals) - {0}\n",
    "                # valid digits are those in [1..9] not in used_vals\n",
    "                all_digits = set(range(1, vocab_size))  # {1,2,...,9} if vocab=10\n",
    "                valid_candidates = all_digits - used_vals\n",
    "\n",
    "                num_candidates = len(valid_candidates)\n",
    "\n",
    "                # Weight logic:\n",
    "                # e.g., let weight = num_candidates\n",
    "                # or weight = 1 + num_candidates, or scale by some factor\n",
    "                # The bigger the number of candidates => the bigger the weight\n",
    "                weights[b, idx] = float(num_candidates)\n",
    "\n",
    "    # Optionally normalize weights per puzzle\n",
    "    weights = weights / (weights.max(dim=1, keepdim=True)[0].clamp(min=1.0) + 1e-8)\n",
    "\n",
    "    return weights\n",
    "\n",
    "def diffusion_train_step(\n",
    "    model,\n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    optimizer,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    loss_fn,\n",
    "    zero_bias=0.8,\n",
    "    use_weighted_loss=False\n",
    "):\n",
    "    # Ensure input tensors are on the correct device and have the right type\n",
    "    puzzle = puzzle.to(dtype=torch.long, device=device)\n",
    "    solution = solution.to(dtype=torch.long, device=device)\n",
    "\n",
    "    # Get a random diffusion step\n",
    "    T = len(schedule)\n",
    "    t_int = np.random.randint(1, T + 1)\n",
    "    t_tensor = torch.tensor([t_int] * puzzle.size(0), device=device)\n",
    "\n",
    "    # Generate noisy puzzle (x_t)\n",
    "    x_t = forward_diffusion_mixed(puzzle, solution, t_int, schedule, vocab_size, device, zero_bias=zero_bias)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.cuda.amp.autocast():  # Ensure everything is within autocast\n",
    "        logits = model(puzzle, x_t, t_tensor)  # Shape: (batch, 163, vocab_size)\n",
    "\n",
    "        # Extract logits for the solution part\n",
    "        logits_solution_part = logits[:, 82:, :]  # Shape: (batch, 81, vocab_size)\n",
    "\n",
    "        # Compute cross-entropy loss\n",
    "        ce_loss = loss_fn(\n",
    "            logits_solution_part.reshape(-1, vocab_size),\n",
    "            solution.reshape(-1)\n",
    "        )\n",
    "\n",
    "        if use_weighted_loss:\n",
    "            # Compute subgoal weights if enabled\n",
    "            weights = compute_subgoal_weights(puzzle, solution, vocab_size).to(device)\n",
    "            weights_flat = weights.reshape(-1)\n",
    "\n",
    "            # Compute per-token loss (NLL)\n",
    "            nll_per_token = torch.nn.functional.cross_entropy(\n",
    "                logits_solution_part.reshape(-1, vocab_size),\n",
    "                solution.reshape(-1),\n",
    "                reduction='none'\n",
    "            )\n",
    "\n",
    "            # Apply subgoal weights\n",
    "            weighted_nll = nll_per_token * weights_flat\n",
    "\n",
    "            # Compute final weighted loss\n",
    "            loss = weighted_nll.mean()\n",
    "        else:\n",
    "            loss = ce_loss\n",
    "\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5) Validation step\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def diffusion_eval_step(\n",
    "    model, \n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs a forward pass during evaluation with time conditioning.\n",
    "\n",
    "    Args:\n",
    "        model: The PuzzleDenoiser model with time conditioning.\n",
    "        puzzle: Tensor of shape (batch, 81) with puzzle digits (0 for blanks).\n",
    "        solution: Tensor of shape (batch, 81) with solution digits.\n",
    "        schedule: The diffusion schedule object containing alphas and T.\n",
    "        loss_fn: The loss function, e.g., nn.CrossEntropyLoss().\n",
    "        vocab_size: Size of the vocabulary (digits 0-9 => 10).\n",
    "        device: torch.device to perform computations on.\n",
    "\n",
    "    Returns:\n",
    "        loss: The evaluation loss as a float.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # 1. Sample a random diffusion step t for the entire batch\n",
    "    T = schedule.T\n",
    "    t_int = np.random.randint(1, T + 1)  # Sample t in [1, T]\n",
    "    # Create a tensor of shape (batch_size,) filled with t_int\n",
    "    t_tensor = torch.full((puzzle.size(0),), t_int, dtype=torch.long, device=device)\n",
    "\n",
    "    # 2. Create x_t with forward diffusion\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t_int, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    # 3. Forward pass with time conditioning\n",
    "    logits = model(puzzle, x_t, t_tensor)  # shape: (batch, 162, vocab_size)\n",
    "\n",
    "    # 4. Slice out the solution part\n",
    "    logits_solution_part = logits[:, 81:, :]  # Include only solution tokens\n",
    "\n",
    "    # 5. Compute cross-entropy loss\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),  # (batch*81, vocab_size)\n",
    "        solution.reshape(-1)                           # (batch*81,)\n",
    "    )\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 6) Iterative decoding to fill blank cells\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def iterative_decode(\n",
    "    model,\n",
    "    puzzle,        # shape (batch, 81) puzzle givens\n",
    "    schedule,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    steps=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Iteratively decodes the puzzle by denoising from t=T to t=1 with time conditioning.\n",
    "\n",
    "    Args:\n",
    "        model: The trained diffusion model.\n",
    "        puzzle: (batch, 81) Input puzzle with given digits and blanks.\n",
    "        schedule: The diffusion schedule object.\n",
    "        vocab_size: Total vocabulary size (e.g., 10 for digits 0-9).\n",
    "        device: Torch device for evaluation (e.g., 'cuda').\n",
    "        steps: Optional; number of decoding steps (defaults to schedule.T).\n",
    "\n",
    "    Returns:\n",
    "        x_t: The final decoded solution (batch, 81).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    batch_size, seq_len = puzzle.shape\n",
    "    T = schedule.T if steps is None else steps\n",
    "\n",
    "    # Initialize x_t: noise only in blank positions\n",
    "    x_t = puzzle.clone()\n",
    "    blank_mask = (puzzle == 0)\n",
    "    x_t[blank_mask] = torch.randint(0, vocab_size, x_t[blank_mask].shape, device=device)\n",
    "\n",
    "    for curr_t in range(T, 0, -1):\n",
    "        # Create a tensor of the current step, repeated for the batch\n",
    "        t_tensor = torch.full((batch_size,), curr_t, dtype=torch.long, device=device)\n",
    "\n",
    "        # Forward pass with time conditioning\n",
    "        logits = model(puzzle, x_t, t_tensor)  # shape: (batch, 162, vocab_size)\n",
    "\n",
    "        # Slice out the solution part\n",
    "        logits_solution_part = logits[:, 81:, :]  # Include only solution tokens\n",
    "\n",
    "        # Predict the solution tokens\n",
    "        pred_sol = logits_solution_part.argmax(dim=-1)  # shape: (batch, 81)\n",
    "\n",
    "        # Update only blank cells\n",
    "        x_t[blank_mask] = pred_sol[blank_mask]\n",
    "\n",
    "    return x_t  # Final filled solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_combined(\n",
    "    model, \n",
    "    schedule,\n",
    "    loader,        # A DataLoader for validation\n",
    "    device,\n",
    "    loss_fn,\n",
    "    vocab_size=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines validation loss, solve rate, and token accuracy in one pass.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    solved_count = 0\n",
    "    correct_token_count = 0\n",
    "    total_token_count = 0\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for puzzles, solutions in tqdm(loader, desc=\"Validation\"):\n",
    "            puzzles = puzzles.to(device)\n",
    "            solutions = solutions.to(device)\n",
    "            batch_size = puzzles.size(0)\n",
    "\n",
    "            # 1) Compute a random t for the entire batch and get x_t\n",
    "            t_int = np.random.randint(1, schedule.T + 1)\n",
    "            t_tensor = torch.full((batch_size,), t_int, dtype=torch.long, device=device)\n",
    "\n",
    "            x_t = forward_diffusion_with_puzzle(\n",
    "                puzzle=puzzles,\n",
    "                solution=solutions,\n",
    "                t=t_int,\n",
    "                schedule=schedule,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 2) Forward pass with time conditioning\n",
    "            logits = model(puzzles, x_t, t_tensor)                  # shape (batch, 162, vocab_size)\n",
    "            logits_solution_part = logits[:, 81:, :]                # only solution part\n",
    "            \n",
    "            # 3) Compute cross-entropy loss\n",
    "            loss = loss_fn(\n",
    "                logits_solution_part.reshape(-1, vocab_size),\n",
    "                solutions.reshape(-1)\n",
    "            )\n",
    "            \n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # 4) Iterative decode to get final filled boards\n",
    "            x_filled = iterative_decode(\n",
    "                model=model,\n",
    "                puzzle=puzzles,\n",
    "                schedule=schedule,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            \n",
    "            # 5) Solve rate: how many boards are 100% correct\n",
    "            eq_mask = (x_filled == solutions)          # (batch, 81)\n",
    "            batch_solved = eq_mask.all(dim=1).sum().item()\n",
    "            solved_count += batch_solved\n",
    "\n",
    "            # 6) Token accuracy on masked cells\n",
    "            masked_mask = (puzzles == 0)               # (batch, 81)\n",
    "            correct_masked = eq_mask & masked_mask      # Correct predictions on masked cells\n",
    "            correct_token_count += correct_masked.sum().item()\n",
    "            total_token_count += masked_mask.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    solve_rate = solved_count / total_samples\n",
    "    token_acc = correct_token_count / total_token_count if total_token_count > 0 else 0.0\n",
    "\n",
    "    return avg_loss, solve_rate, token_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 7) Putting it all together: example training loop\n",
    "# ------------------------------------------------------------------------\n",
    "def train_puzzle_diffusion(\n",
    "    X_train, y_train, \n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50,\n",
    "    best_model_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the PuzzleDenoiser model with time-conditioned diffusion.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    schedule = SigmoidDiffusionSchedule(\n",
    "        T=T, \n",
    "        min_alpha=0.02, \n",
    "        max_alpha=0.7,\n",
    "        k=12.0\n",
    "    )\n",
    "\n",
    "    # Handle multi-GPU setup\n",
    "    multi_gpu = torch.cuda.device_count() > 1\n",
    "    if multi_gpu:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    else:\n",
    "        print(\"Using 1 GPU or CPU.\")\n",
    "\n",
    "    # Initialize the model with max_T matching the schedule\n",
    "    model = PuzzleDenoiser(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_heads=num_heads, \n",
    "        num_layers=num_layers,\n",
    "        max_T=T\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if provided (handling DataParallel)\n",
    "    if best_model_path is not None:\n",
    "        state_dict = torch.load(best_model_path, map_location=device)\n",
    "        \n",
    "        if multi_gpu and not list(state_dict.keys())[0].startswith('module.'):\n",
    "            model.load_state_dict(state_dict)\n",
    "            model = nn.DataParallel(model)\n",
    "        elif not multi_gpu and list(state_dict.keys())[0].startswith('module.'):\n",
    "            new_state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            model.load_state_dict(state_dict)\n",
    "            \n",
    "        print(f\"Loaded model from {best_model_path}\")\n",
    "    elif multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    # Add learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True\n",
    "    )\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Setup data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset   = TensorDataset(X_val,   y_val)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader    = DataLoader(val_dataset,   batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    # Initial validation before training\n",
    "    if False:\n",
    "        print(\"Running initial validation (Epoch 0):\")\n",
    "        avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "        print(f\"Initial val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Initial solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "        print(f\"Initial token-level accuracy on validation set: {val_token_acc*100:.2f}%\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_puzzle, batch_solution in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "            # Use autocast for mixed precision training\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss_val = diffusion_train_step(\n",
    "                    model=model,\n",
    "                    puzzle=batch_puzzle,\n",
    "                    solution=batch_solution,\n",
    "                    schedule=schedule,\n",
    "                    optimizer=optimizer,\n",
    "                    loss_fn=loss_fn,\n",
    "                    vocab_size=vocab_size,\n",
    "                    device=device\n",
    "                )\n",
    "            \n",
    "            # Scale loss and do backward pass\n",
    "            scaler.scale(loss_val).backward()\n",
    "            \n",
    "            # Unscale gradients and optimizer step\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_losses.append(loss_val.item())\n",
    "            \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # Validation\n",
    "        avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "        print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"puzzle_diffuser_best.pt\")\n",
    "            print(f\"  [*] Best model saved @ val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return model, schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load sudoku data\n",
    "df = pd.read_csv('./data/sudoku.csv')\n",
    "\n",
    "# Convert strings to tensors\n",
    "def preprocess_sudoku(puzzle_str):\n",
    "    # Convert string to list of integers and then to tensor\n",
    "    return torch.tensor([int(d) for d in puzzle_str], dtype=torch.long)\n",
    "\n",
    "# Convert all puzzles and solutions\n",
    "puzzles = torch.stack([preprocess_sudoku(p) for p in df['quizzes']])\n",
    "solutions = torch.stack([preprocess_sudoku(s) for s in df['solutions']])\n",
    "\n",
    "# Karpathy split (90/5/5)\n",
    "train_size = 0.9\n",
    "val_size = 0.05\n",
    "test_size = 0.05\n",
    "\n",
    "# First split into train and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    puzzles, solutions, train_size=train_size, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into val and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50\n",
    "    #best_model_path=\"puzzle_diffuser_best.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drob7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_33480\\2404183206.py:72: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 2 GPUs!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/14063 [00:00<?, ?it/s]C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_33480\\2404183206.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\drob7\\AppData\\Local\\Temp\\ipykernel_33480\\3673127547.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Ensure everything is within autocast\n",
      "Epoch 1 [Train]:   0%|          | 0/14063 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (5120) to match target batch_size (5184).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, schedule \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_puzzle_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#best_model_path=\"puzzle_diffuser_best.pt\"\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[43], line 103\u001b[0m, in \u001b[0;36mtrain_puzzle_diffusion\u001b[1;34m(X_train, y_train, X_val, y_val, vocab_size, T, embed_dim, num_heads, num_layers, batch_size, num_epochs, best_model_path)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_puzzle, batch_solution \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Use autocast for mixed precision training\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 103\u001b[0m         loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpuzzle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_puzzle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_solution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschedule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# Scale loss and do backward pass\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss_val)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn[47], line 98\u001b[0m, in \u001b[0;36mdiffusion_train_step\u001b[1;34m(model, puzzle, solution, schedule, optimizer, vocab_size, device, loss_fn, zero_bias, use_weighted_loss)\u001b[0m\n\u001b[0;32m     95\u001b[0m logits_solution_part \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m82\u001b[39m:, :]  \u001b[38;5;66;03m# Shape: (batch, 81, vocab_size)\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Compute cross-entropy loss\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m ce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_solution_part\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_weighted_loss:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Compute subgoal weights if enabled\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     weights \u001b[38;5;241m=\u001b[39m compute_subgoal_weights(puzzle, solution, vocab_size)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (5120) to match target batch_size (5184)."
     ]
    }
   ],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=80,\n",
    "    embed_dim=256,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    batch_size=64,\n",
    "    num_epochs=100\n",
    "    #best_model_path=\"puzzle_diffuser_best.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2) CREATE THE NEW SCHEDULE\n",
    "#############################################\n",
    "schedule = OneFlipDiffusionSchedule(\n",
    "    T=80\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# 3) PICK A SAMPLE PUZZLE & SOLUTION\n",
    "#############################################\n",
    "sample_puzzle = X_train[0:1]\n",
    "sample_solution = y_train[0:1]\n",
    "\n",
    "print(\"Puzzle:\", sample_puzzle)\n",
    "print(\"Solution:\", sample_solution)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#############################################\n",
    "# 4) SHOW x_1, x_2, ... x_T\n",
    "#############################################\n",
    "vocab_size = 10  # digits 0-9\n",
    "for t in range(1, schedule.T + 1):\n",
    "    x_t = forward_diffusion_mixed(X_train[:1], y_train[:1], t, schedule, vocab_size=10, device=device, bias_increment=1.3)\n",
    "    print(f\"x_t at t={t}:\", x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iterative_decode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Then to do iterative decoding:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m puzzle_batch \u001b[38;5;241m=\u001b[39m X_val[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# for example\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x_filled \u001b[38;5;241m=\u001b[39m \u001b[43miterative_decode\u001b[49m(\n\u001b[0;32m      5\u001b[0m     model, \n\u001b[0;32m      6\u001b[0m     puzzle\u001b[38;5;241m=\u001b[39mpuzzle_batch, \n\u001b[0;32m      7\u001b[0m     schedule\u001b[38;5;241m=\u001b[39mschedule, \n\u001b[0;32m      8\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      9\u001b[0m     device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPuzzle: \u001b[39m\u001b[38;5;124m\"\u001b[39m, puzzle_batch)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded solution: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x_filled)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iterative_decode' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Then to do iterative decoding:\n",
    "puzzle_batch = X_val[0:2]  # for example\n",
    "x_filled = iterative_decode(\n",
    "    model, \n",
    "    puzzle=puzzle_batch, \n",
    "    schedule=schedule, \n",
    "    vocab_size=10,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Puzzle: \", puzzle_batch)\n",
    "print(\"Decoded solution: \", x_filled)\n",
    "print(\"Original solution: \", y_val[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = measure_sudoku_solve_rate(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val[0:100],\n",
    "    y_val[0:100],\n",
    "    device=device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Solve rate on validation set: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small validation dataset for testing\n",
    "X_val_test = X_val[:1000]\n",
    "y_val_test = y_val[:1000]\n",
    "test_val_loader = DataLoader(\n",
    "    TensorDataset(X_val_test, y_val_test),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run validation\n",
    "avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "    model=model,\n",
    "    schedule=schedule, \n",
    "    loader=test_val_loader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

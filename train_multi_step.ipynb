{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 1) A discrete and Sigmoid diffusion schedule\n",
    "# ------------------------------------------------------------------------\n",
    "class DiscreteDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Simple linear schedule of alpha_t from t=1..T,\n",
    "    where alpha_t = min_alpha + (max_alpha - min_alpha)*(t/T).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=10, min_alpha=0.1, max_alpha=0.7):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            frac = t / T\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha)*frac\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t-1]\n",
    "\n",
    "class SigmoidDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Sigmoid schedule of alpha_t from t=1..T.\n",
    "\n",
    "    alpha_t = min_alpha + (max_alpha - min_alpha)*sigmoid(k*(frac - 0.5)),\n",
    "    where frac = (t-1)/(T-1).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=30, min_alpha=0.1, max_alpha=0.7, k=12.0):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            # frac in [0..1]\n",
    "            frac = (t - 1) / (T - 1)  \n",
    "            # logistic\n",
    "            s = 1 / (1 + math.exp(-k * (frac - 0.5)))\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha) * s\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 2) Forward noising that respects puzzle givens\n",
    "# ------------------------------------------------------------------------\n",
    "def forward_diffusion_with_puzzle(puzzle, solution, t, schedule, vocab_size, device):\n",
    "    \"\"\"\n",
    "    puzzle:   (batch, 81) with digits in [0..9]. 0 means blank, non-zero means given.\n",
    "    solution: (batch, 81) correct final solution\n",
    "    t:        an integer in [1..T]\n",
    "    schedule: contains alpha_t\n",
    "    returns x_t: partially noised solution (batch, 81)\n",
    "        - givens remain the same as solution's corresponding digit\n",
    "        - blank positions get replaced with random digits w.p. alpha_t\n",
    "    \"\"\"\n",
    "    alpha_t = schedule[t]  # fraction to noise\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Where puzzle is nonzero => givens => do NOT overwrite\n",
    "    givens_mask = (puzzle != 0)\n",
    "\n",
    "    # We'll noise only the positions that are blank in the puzzle\n",
    "    #   i.e. puzzle[i] == 0 => we can noise solution[i].\n",
    "    blank_mask = (puzzle == 0)\n",
    "\n",
    "    # Create random noise from [0..vocab_size-1] for the blank positions\n",
    "    noise = torch.randint(0, vocab_size, solution.shape, device=device)\n",
    "\n",
    "    # Decide which blank positions to replace with noise\n",
    "    replace_mask = (torch.rand_like(solution.float()) < alpha_t) & blank_mask\n",
    "\n",
    "    # x_t: start from the true solution, then replace with noise for some blank cells\n",
    "    x_t = solution.clone()\n",
    "    x_t[replace_mask] = noise[replace_mask]\n",
    "\n",
    "    # givens remain the same as the correct solution digit at that position\n",
    "    # (actually, this is already the default if puzzle != 0, but we do not overwrite them)\n",
    "    # so x_t[givens_mask] = solution[givens_mask] # if you want to be explicit\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3) The model sees puzzle+partially noised solution as input\n",
    "# ------------------------------------------------------------------------\n",
    "class PuzzleDenoiser(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer that takes [puzzle || x_t] => shape (batch, 162) tokens\n",
    "    and outputs a distribution over solution tokens for the second half.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, puzzle, x_t):\n",
    "        \"\"\"\n",
    "        puzzle, x_t: (batch, 81)\n",
    "        We'll embed => shape (batch, 162, embed_dim)\n",
    "        Return shape => (batch, 162, vocab_size),\n",
    "        but we'll only evaluate the second half in the loss.\n",
    "        \"\"\"\n",
    "        batch_size = puzzle.size(0)\n",
    "        # Concatenate\n",
    "        inp = torch.cat([puzzle, x_t], dim=1)  # (batch, 162)\n",
    "        emb = self.embedding(inp)             # => (batch, 162, embed_dim)\n",
    "        enc_out = self.encoder(emb)           # => (batch, 162, embed_dim)\n",
    "        logits = self.output_layer(enc_out)   # => (batch, 162, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4) Diffusion train step\n",
    "# ------------------------------------------------------------------------\n",
    "def diffusion_train_step(\n",
    "    model, \n",
    "    puzzle,      # (batch, 81)\n",
    "    solution,    # (batch, 81)\n",
    "    schedule,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Move to device\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Sample a random t\n",
    "    T = schedule.T\n",
    "    t = np.random.randint(1, T+1)\n",
    "\n",
    "    # Create x_t that doesn't overwrite puzzle givens\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    # Forward pass [puzzle || x_t]\n",
    "    logits = model(puzzle, x_t)  # shape (batch, 162, vocab_size)\n",
    "\n",
    "    # We only care about the second half (positions 81..161) \n",
    "    # for the solution. The first half is puzzle context.\n",
    "    logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "    # Compare to ground truth solution\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),\n",
    "        solution.reshape(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5) Validation step\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def diffusion_eval_step(\n",
    "    model, \n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    t = np.random.randint(1, schedule.T+1)\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    logits = model(puzzle, x_t)\n",
    "    logits_solution_part = logits[:, 81:, :]  # only second half\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),\n",
    "        solution.reshape(-1)\n",
    "    )\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 6) Iterative decoding to fill blank cells\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def iterative_decode(\n",
    "    model,\n",
    "    puzzle,        # shape (batch, 81) puzzle givens\n",
    "    schedule,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    steps=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Start from x_T = fully noised in blank cells (or partial).\n",
    "      2) For t in [T..1], model predicts solution => we partially adopt it in blank cells\n",
    "         respecting puzzle givens.\n",
    "      3) Return final x_0\n",
    "    If steps=None => run the full T steps from schedule.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    batch_size, seq_len = puzzle.shape\n",
    "    T = schedule.T if steps is None else steps\n",
    "\n",
    "    # Initialize x_t: fully noised in blank positions, puzzle givens remain correct solution digits \n",
    "    # (We don't have the solution during inference, so let's use puzzle for givens \n",
    "    #  and random for blanks)\n",
    "    x_t = puzzle.clone()\n",
    "    blank_mask = (puzzle == 0)\n",
    "    # fill blanks with random\n",
    "    x_t[blank_mask] = torch.randint(0, vocab_size, x_t[blank_mask].shape, device=device)\n",
    "\n",
    "    for t in range(T, 0, -1):\n",
    "        # forward pass\n",
    "        logits = model(puzzle, x_t)         # (batch, 162, vocab_size)\n",
    "        logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "        # predicted solution tokens for second half\n",
    "        pred_sol = logits_solution_part.argmax(dim=-1)  # (batch, 81)\n",
    "\n",
    "        # Now adopt the model's predictions *only* in blank cells.\n",
    "        # Keep puzzle givens as-is. But if puzzle[i] was 0, we update from pred_sol.\n",
    "        x_t[blank_mask] = pred_sol[blank_mask]\n",
    "\n",
    "        # Optionally, you can do partial or probabilistic \"denoising\" \n",
    "        # (like in the paper). For simplicity, we do a 1-step \"take argmax\" each iteration.\n",
    "\n",
    "    return x_t  # hopefully a filled solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_combined(\n",
    "    model,\n",
    "    schedule,\n",
    "    loader,        # A DataLoader for validation\n",
    "    device,\n",
    "    loss_fn,\n",
    "    vocab_size=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines:\n",
    "      - validation loss (random t)\n",
    "      - solve rate\n",
    "      - token accuracy\n",
    "    into one pass over the val set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    solved_count = 0\n",
    "    correct_token_count = 0\n",
    "    total_token_count = 0\n",
    "\n",
    "    for puzzles, solutions in tqdm(loader, desc=\"Validation\"):\n",
    "        puzzles = puzzles.to(device)\n",
    "        solutions = solutions.to(device)\n",
    "        batch_size = puzzles.size(0)\n",
    "\n",
    "        # 1) Compute a random t for the entire batch and get x_t\n",
    "        t = np.random.randint(1, schedule.T + 1)\n",
    "        x_t = forward_diffusion_with_puzzle(\n",
    "            puzzle=puzzles,\n",
    "            solution=solutions,\n",
    "            t=t,\n",
    "            schedule=schedule,\n",
    "            vocab_size=vocab_size,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # 2) Forward pass, compute cross-entropy loss\n",
    "        logits = model(puzzles, x_t)                  # shape (batch, 162, vocab_size)\n",
    "        logits_solution_part = logits[:, 81:, :]      # only second half\n",
    "        loss = loss_fn(\n",
    "            logits_solution_part.reshape(-1, vocab_size),\n",
    "            solutions.reshape(-1)\n",
    "        )\n",
    "        \n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        # 3) Iterative decode to get final filled boards\n",
    "        x_filled = iterative_decode(\n",
    "            model=model,\n",
    "            puzzle=puzzles,\n",
    "            schedule=schedule,\n",
    "            vocab_size=vocab_size,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # 4) Solve rate: how many boards are 100% correct\n",
    "        eq_mask = (x_filled == solutions)          # (batch, 81)\n",
    "        batch_solved = eq_mask.all(dim=1).sum().item()\n",
    "        solved_count += batch_solved\n",
    "\n",
    "        # 5) Token accuracy across all puzzles/tokens\n",
    "        correct_token_count += eq_mask.sum().item()\n",
    "        total_token_count += eq_mask.numel()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    solve_rate = solved_count / total_samples\n",
    "    token_acc = correct_token_count / total_token_count\n",
    "\n",
    "    return avg_loss, solve_rate, token_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 7) Putting it all together: example training loop\n",
    "# ------------------------------------------------------------------------\n",
    "def train_puzzle_diffusion(\n",
    "    X_train, y_train, \n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=30,\n",
    "    embed_dim=256,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    batch_size=32,\n",
    "    num_epochs=5,\n",
    "    best_model_path=None\n",
    "):\n",
    "    \"\"\"\n",
    "    X_* are puzzle arrays of shape (N, 81).\n",
    "    y_* are solution arrays of shape (N, 81).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    schedule = SigmoidDiffusionSchedule(\n",
    "        T=T, \n",
    "        min_alpha=0.1, \n",
    "        max_alpha=0.7,\n",
    "        k = 12.0\n",
    "    )\n",
    "\n",
    "    # Handle multi-GPU setup first\n",
    "    multi_gpu = torch.cuda.device_count() > 1\n",
    "    if multi_gpu:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    else:\n",
    "        print(\"Using 1 GPU or CPU.\")\n",
    "\n",
    "    # Create base model\n",
    "    model = PuzzleDenoiser(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_heads=num_heads, \n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "\n",
    "    # Load best model if provided\n",
    "    if best_model_path is not None:\n",
    "        state_dict = torch.load(best_model_path, map_location=device)\n",
    "        \n",
    "        # If saved model wasn't using DataParallel but we are now\n",
    "        if multi_gpu and not list(state_dict.keys())[0].startswith('module.'):\n",
    "            # First load state dict into base model\n",
    "            model.load_state_dict(state_dict)\n",
    "            # Then wrap in DataParallel\n",
    "            model = nn.DataParallel(model)\n",
    "        # If saved model was using DataParallel but we aren't now \n",
    "        elif not multi_gpu and list(state_dict.keys())[0].startswith('module.'):\n",
    "            new_state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "            model.load_state_dict(new_state_dict)\n",
    "        # If DataParallel usage matches\n",
    "        else:\n",
    "            model.load_state_dict(state_dict)\n",
    "            \n",
    "        print(f\"Loaded model from {best_model_path}\")\n",
    "    # Wrap in DataParallel if using multiple GPUs and not loading saved model\n",
    "    elif multi_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setup data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset   = TensorDataset(X_val,   y_val)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader    = DataLoader(val_dataset,   batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_puzzle, batch_solution in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "            loss_val = diffusion_train_step(\n",
    "                model=model,\n",
    "                puzzle=batch_puzzle,\n",
    "                solution=batch_solution,\n",
    "                schedule=schedule,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            train_losses.append(loss_val)\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # ----------------------------\n",
    "        # VALIDATION (Combined)\n",
    "        # ----------------------------\n",
    "        avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "                \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "        print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"puzzle_diffuser_best.pt\")\n",
    "            print(f\"  [*] Best model saved @ val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return model, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mint\u001b[39m(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m puzzle_str], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert all puzzles and solutions\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m puzzles \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mpreprocess_sudoku\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquizzes\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     15\u001b[0m solutions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([preprocess_sudoku(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolutions\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Karpathy split (90/5/5)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[68], line 11\u001b[0m, in \u001b[0;36mpreprocess_sudoku\u001b[1;34m(puzzle_str)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_sudoku\u001b[39m(puzzle_str):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Convert string to list of integers and then to tensor\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpuzzle_str\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load sudoku data\n",
    "df = pd.read_csv('./data/sudoku.csv')\n",
    "\n",
    "# Convert strings to tensors\n",
    "def preprocess_sudoku(puzzle_str):\n",
    "    # Convert string to list of integers and then to tensor\n",
    "    return torch.tensor([int(d) for d in puzzle_str], dtype=torch.long)\n",
    "\n",
    "# Convert all puzzles and solutions\n",
    "puzzles = torch.stack([preprocess_sudoku(p) for p in df['quizzes']])\n",
    "solutions = torch.stack([preprocess_sudoku(s) for s in df['solutions']])\n",
    "\n",
    "# Karpathy split (90/5/5)\n",
    "train_size = 0.9\n",
    "val_size = 0.05\n",
    "test_size = 0.05\n",
    "\n",
    "# First split into train and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    puzzles, solutions, train_size=train_size, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into val and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using 2 GPUs!\n",
      "Loaded model from puzzle_diffuser_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   0%|          | 0/14063 [00:00<?, ?it/s]C:\\Users\\drob7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn(\"PyTorch is not compiled with NCCL support\")\n",
      "Epoch 1 [Train]:   2%|▏         | 222/14063 [00:38<38:53,  5.93it/s]"
     ]
    }
   ],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50,\n",
    "    best_model_path=\"puzzle_diffuser_best.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]])\n",
      "Solution: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]])\n",
      "x_1 (alpha=0.101) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 4, 1, 8,\n",
      "         4, 1, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 9, 4, 5, 9, 2,\n",
      "         4, 9, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_2 (alpha=0.102) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 2, 4, 4, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_3 (alpha=0.103) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 6, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 9, 6, 6, 9, 3, 9, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 4]], device='cuda:0')\n",
      "x_4 (alpha=0.105) = tensor([[1, 4, 2, 3, 1, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 0, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 9, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 6, 7, 6, 1]], device='cuda:0')\n",
      "x_5 (alpha=0.108) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 7, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 8, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_6 (alpha=0.112) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 2, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 7, 9, 3, 1, 5, 5, 5, 5, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 1, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_7 (alpha=0.117) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 7, 5, 2, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 4, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         6, 2, 9, 8, 5, 6, 7, 6, 4]], device='cuda:0')\n",
      "x_8 (alpha=0.126) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 5, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 5, 6, 6, 9, 3, 2, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 1, 1, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_9 (alpha=0.138) = tensor([[1, 4, 2, 3, 0, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 4, 5, 4, 9, 7, 8, 1, 1, 6, 6, 9, 3, 1, 2, 5, 8, 8, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 1, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         7, 2, 5, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_10 (alpha=0.156) = tensor([[1, 4, 2, 3, 8, 9, 8, 7, 5, 9, 8, 7, 5, 4, 7, 1, 7, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 6, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 9, 7, 1, 4, 5, 9, 2,\n",
      "         4, 7, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_11 (alpha=0.181) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 3, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 6, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 8, 5, 8, 4, 7, 2, 1, 8,\n",
      "         4, 3, 6, 2, 5, 6, 9, 6, 7, 2, 9, 8, 4, 3, 8, 8, 3, 2, 7, 5, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 2, 1]], device='cuda:0')\n",
      "x_12 (alpha=0.214) = tensor([[1, 4, 2, 3, 8, 9, 5, 7, 5, 9, 8, 6, 5, 3, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 8, 6, 7, 2, 9, 1, 4, 3, 8, 8, 8, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 6, 7, 8, 5, 9, 7, 6, 1]], device='cuda:0')\n",
      "x_13 (alpha=0.257) = tensor([[1, 4, 2, 3, 2, 9, 6, 7, 5, 9, 8, 1, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 5, 4, 7, 1, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 6, 6, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 4, 2, 6, 7, 8, 9, 1, 4, 3, 8, 8, 3, 1, 7, 5, 5, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 4, 7, 6, 1]], device='cuda:0')\n",
      "x_14 (alpha=0.310) = tensor([[1, 4, 2, 8, 3, 9, 6, 7, 5, 9, 8, 3, 5, 4, 7, 1, 6, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 4, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 8, 8, 4, 9, 2, 1, 8,\n",
      "         4, 8, 6, 2, 5, 9, 6, 6, 7, 2, 6, 2, 4, 3, 8, 8, 3, 8, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 8, 1]], device='cuda:0')\n",
      "x_15 (alpha=0.369) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 4, 2, 3, 3, 7, 5, 6, 1, 9,\n",
      "         9, 0, 4, 2, 9, 4, 9, 7, 8, 3, 1, 6, 6, 3, 3, 1, 8, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 8, 6, 2, 5, 9, 5, 6, 7, 5, 9, 8, 4, 3, 8, 8, 4, 6, 7, 6, 0, 5, 9, 2,\n",
      "         4, 1, 9, 0, 5, 3, 4, 6, 1]], device='cuda:0')\n",
      "x_16 (alpha=0.431) = tensor([[6, 4, 2, 3, 8, 9, 9, 7, 5, 9, 8, 4, 5, 4, 7, 1, 0, 3, 3, 2, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 2, 4, 9, 7, 8, 4, 1, 6, 6, 9, 3, 1, 2, 5, 8, 1, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 5, 6, 7, 5, 9, 9, 4, 3, 8, 8, 3, 2, 7, 6, 5, 5, 9, 2,\n",
      "         1, 2, 5, 8, 5, 3, 9, 4, 8]], device='cuda:0')\n",
      "x_17 (alpha=0.490) = tensor([[1, 4, 2, 9, 8, 9, 6, 7, 5, 9, 8, 6, 7, 1, 7, 2, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 4, 1, 5, 4, 9, 7, 8, 3, 5, 6, 6, 9, 3, 1, 2, 5, 2, 4, 6, 5, 1, 8,\n",
      "         4, 3, 6, 2, 8, 6, 3, 6, 7, 3, 9, 0, 4, 3, 8, 8, 3, 8, 7, 8, 4, 0, 9, 2,\n",
      "         9, 2, 9, 2, 5, 0, 8, 6, 8]], device='cuda:0')\n",
      "x_18 (alpha=0.543) = tensor([[3, 4, 2, 1, 8, 9, 6, 7, 5, 9, 2, 4, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 6,\n",
      "         9, 5, 3, 2, 5, 4, 9, 7, 8, 8, 1, 6, 2, 0, 3, 2, 9, 5, 8, 4, 9, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 8, 5, 6, 7, 2, 2, 7, 4, 3, 8, 8, 5, 2, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 1, 5, 3, 7, 4, 0]], device='cuda:0')\n",
      "x_19 (alpha=0.586) = tensor([[1, 4, 2, 5, 8, 9, 7, 7, 5, 9, 8, 7, 7, 4, 7, 4, 9, 3, 3, 7, 5, 6, 1, 6,\n",
      "         9, 8, 7, 2, 0, 4, 9, 7, 8, 2, 4, 6, 4, 9, 3, 7, 3, 5, 7, 1, 0, 4, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 0, 6, 7, 2, 4, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         5, 2, 4, 5, 5, 3, 1, 6, 6]], device='cuda:0')\n",
      "x_20 (alpha=0.619) = tensor([[6, 4, 2, 5, 8, 9, 6, 7, 5, 9, 7, 6, 1, 7, 7, 6, 7, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 1, 9, 2, 5, 4, 9, 7, 8, 3, 1, 6, 1, 9, 3, 1, 4, 2, 7, 7, 7, 7, 1, 8,\n",
      "         4, 5, 6, 2, 1, 9, 5, 6, 7, 2, 7, 1, 4, 3, 8, 8, 3, 0, 7, 6, 8, 5, 9, 2,\n",
      "         3, 2, 9, 4, 5, 3, 7, 4, 9]], device='cuda:0')\n",
      "x_21 (alpha=0.644) = tensor([[0, 4, 2, 1, 7, 9, 1, 7, 5, 9, 1, 6, 5, 5, 7, 1, 3, 3, 3, 2, 5, 6, 1, 7,\n",
      "         9, 9, 7, 2, 8, 4, 9, 7, 8, 3, 1, 6, 8, 7, 3, 9, 1, 0, 8, 9, 7, 5, 1, 8,\n",
      "         4, 8, 6, 2, 0, 9, 5, 6, 7, 6, 9, 2, 4, 3, 8, 8, 6, 7, 7, 6, 7, 6, 9, 2,\n",
      "         4, 2, 7, 8, 5, 2, 7, 6, 4]], device='cuda:0')\n",
      "x_22 (alpha=0.662) = tensor([[1, 4, 2, 6, 8, 9, 9, 7, 5, 9, 3, 2, 7, 7, 7, 9, 4, 3, 3, 7, 5, 6, 1, 4,\n",
      "         9, 8, 7, 4, 8, 4, 9, 7, 8, 1, 5, 6, 6, 9, 3, 1, 2, 2, 4, 7, 7, 9, 1, 8,\n",
      "         4, 4, 6, 2, 5, 9, 0, 6, 7, 6, 6, 1, 4, 3, 8, 8, 5, 1, 7, 8, 7, 5, 9, 2,\n",
      "         4, 4, 9, 8, 5, 1, 3, 4, 5]], device='cuda:0')\n",
      "x_23 (alpha=0.674) = tensor([[8, 4, 2, 5, 9, 9, 3, 7, 5, 9, 0, 1, 3, 4, 7, 5, 4, 3, 3, 7, 5, 6, 1, 1,\n",
      "         9, 2, 5, 8, 5, 4, 9, 7, 8, 3, 2, 6, 2, 9, 3, 4, 2, 5, 4, 3, 7, 1, 1, 8,\n",
      "         4, 7, 6, 2, 5, 5, 0, 6, 7, 6, 9, 7, 4, 3, 8, 8, 6, 9, 7, 8, 0, 8, 9, 2,\n",
      "         1, 2, 7, 8, 5, 8, 7, 6, 0]], device='cuda:0')\n",
      "x_24 (alpha=0.683) = tensor([[1, 4, 2, 9, 0, 9, 4, 7, 5, 9, 8, 8, 5, 8, 7, 7, 6, 3, 3, 1, 5, 6, 1, 2,\n",
      "         9, 9, 0, 7, 3, 4, 9, 7, 8, 0, 0, 6, 8, 5, 3, 1, 2, 6, 8, 3, 7, 9, 1, 8,\n",
      "         4, 7, 6, 2, 5, 1, 5, 6, 7, 8, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 7, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 2, 5, 2]], device='cuda:0')\n",
      "x_25 (alpha=0.688) = tensor([[5, 4, 2, 4, 8, 9, 6, 7, 5, 9, 5, 7, 2, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 2, 2, 3, 4, 9, 7, 8, 3, 1, 6, 6, 4, 3, 1, 4, 5, 9, 4, 7, 2, 1, 8,\n",
      "         4, 8, 6, 2, 9, 6, 5, 6, 7, 2, 1, 1, 4, 3, 8, 8, 4, 0, 7, 4, 6, 0, 9, 2,\n",
      "         4, 4, 9, 1, 5, 6, 7, 6, 5]], device='cuda:0')\n",
      "x_26 (alpha=0.692) = tensor([[1, 4, 2, 1, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 4, 5, 6, 1, 7,\n",
      "         9, 1, 8, 0, 8, 4, 9, 7, 8, 3, 1, 6, 3, 6, 3, 6, 0, 4, 7, 4, 8, 4, 1, 8,\n",
      "         4, 9, 6, 2, 6, 4, 5, 6, 7, 2, 2, 4, 4, 3, 8, 8, 0, 9, 7, 6, 4, 5, 9, 2,\n",
      "         9, 8, 1, 4, 5, 6, 7, 6, 3]], device='cuda:0')\n",
      "x_27 (alpha=0.695) = tensor([[3, 4, 2, 1, 8, 9, 8, 7, 5, 9, 4, 6, 8, 1, 7, 0, 2, 3, 3, 0, 5, 6, 1, 5,\n",
      "         9, 8, 4, 2, 4, 4, 9, 7, 8, 7, 1, 6, 9, 4, 3, 7, 0, 9, 6, 4, 8, 3, 1, 8,\n",
      "         4, 3, 6, 2, 2, 1, 2, 6, 7, 4, 6, 1, 4, 3, 8, 8, 3, 1, 7, 6, 8, 5, 9, 2,\n",
      "         4, 7, 8, 6, 5, 9, 9, 6, 5]], device='cuda:0')\n",
      "x_28 (alpha=0.697) = tensor([[1, 4, 2, 2, 6, 9, 6, 7, 5, 9, 4, 6, 7, 1, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 3, 9, 6, 3, 4, 9, 7, 8, 6, 7, 6, 9, 0, 3, 1, 6, 9, 8, 4, 8, 4, 1, 8,\n",
      "         4, 2, 6, 2, 6, 3, 1, 6, 7, 2, 5, 4, 4, 3, 8, 8, 2, 2, 7, 8, 4, 4, 9, 2,\n",
      "         0, 2, 7, 8, 5, 3, 1, 6, 6]], device='cuda:0')\n",
      "x_29 (alpha=0.698) = tensor([[1, 4, 2, 0, 8, 9, 9, 7, 5, 9, 8, 9, 1, 1, 7, 1, 0, 3, 3, 9, 5, 6, 1, 7,\n",
      "         9, 7, 7, 2, 5, 4, 9, 7, 8, 2, 3, 6, 6, 5, 3, 7, 2, 8, 7, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 3, 1, 8, 6, 7, 6, 4, 9, 4, 3, 8, 8, 3, 1, 7, 6, 0, 3, 9, 2,\n",
      "         6, 2, 9, 3, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_30 (alpha=0.699) = tensor([[5, 4, 2, 1, 7, 9, 5, 7, 5, 9, 8, 3, 5, 7, 7, 1, 2, 3, 3, 7, 5, 6, 1, 9,\n",
      "         9, 4, 5, 2, 3, 4, 9, 7, 8, 5, 1, 6, 6, 9, 3, 1, 2, 1, 4, 4, 7, 3, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 0, 6, 7, 2, 3, 3, 4, 3, 8, 8, 5, 8, 7, 2, 4, 5, 9, 2,\n",
      "         4, 5, 0, 4, 5, 4, 7, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2) CREATE THE NEW SCHEDULE\n",
    "#############################################\n",
    "schedule = SigmoidDiffusionSchedule(\n",
    "    T=30,\n",
    "    min_alpha=0.1,\n",
    "    max_alpha=0.7,\n",
    "    k=12.0\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# 3) PICK A SAMPLE PUZZLE & SOLUTION\n",
    "#############################################\n",
    "sample_puzzle = X_train[0:1]\n",
    "sample_solution = y_train[0:1]\n",
    "\n",
    "print(\"Puzzle:\", sample_puzzle)\n",
    "print(\"Solution:\", sample_solution)\n",
    "\n",
    "#############################################\n",
    "# 4) SHOW x_1, x_2, ... x_T\n",
    "#############################################\n",
    "vocab_size = 10  # digits 0-9\n",
    "for t in range(1, schedule.T+1):\n",
    "    alpha_t = schedule[t]  # just to see the noise fraction\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle=sample_puzzle, \n",
    "        solution=sample_solution, \n",
    "        t=t, \n",
    "        schedule=schedule, \n",
    "        vocab_size=vocab_size, \n",
    "        device=device\n",
    "    )\n",
    "    print(f\"x_{t} (alpha={alpha_t:.3f}) =\", x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Then to do iterative decoding:\n",
    "puzzle_batch = X_val[0:2]  # for example\n",
    "x_filled = iterative_decode(\n",
    "    model, \n",
    "    puzzle=puzzle_batch, \n",
    "    schedule=schedule, \n",
    "    vocab_size=10,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Puzzle: \", puzzle_batch)\n",
    "print(\"Decoded solution: \", x_filled)\n",
    "print(\"Original solution: \", y_val[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Solve Rate: 100%|██████████| 4/4 [00:00<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve rate on validation set: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = measure_sudoku_solve_rate(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val[0:100],\n",
    "    y_val[0:100],\n",
    "    device=device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Solve rate on validation set: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.6878\n",
      "Solve rate on validation set: 0.00%\n",
      "Token-level accuracy on validation set: 48.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a small validation dataset for testing\n",
    "X_val_test = X_val[200:300]\n",
    "y_val_test = y_val[200:300]\n",
    "test_val_loader = DataLoader(\n",
    "    TensorDataset(X_val_test, y_val_test),\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Initialize loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Run validation\n",
    "avg_val_loss, val_solve_rate, val_token_acc = validate_combined(\n",
    "    model=model,\n",
    "    schedule=schedule, \n",
    "    loader=test_val_loader,\n",
    "    device=device,\n",
    "    loss_fn=loss_fn,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "print(f\"Solve rate on validation set: {val_solve_rate*100:.2f}%\")\n",
    "print(f\"Token-level accuracy on validation set: {val_token_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

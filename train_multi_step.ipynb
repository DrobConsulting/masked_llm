{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 1) A discrete and Sigmoid diffusion schedule\n",
    "# ------------------------------------------------------------------------\n",
    "class DiscreteDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Simple linear schedule of alpha_t from t=1..T,\n",
    "    where alpha_t = min_alpha + (max_alpha - min_alpha)*(t/T).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=10, min_alpha=0.1, max_alpha=0.7):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            frac = t / T\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha)*frac\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t-1]\n",
    "\n",
    "class SigmoidDiffusionSchedule:\n",
    "    \"\"\"\n",
    "    Sigmoid schedule of alpha_t from t=1..T.\n",
    "\n",
    "    alpha_t = min_alpha + (max_alpha - min_alpha)*sigmoid(k*(frac - 0.5)),\n",
    "    where frac = (t-1)/(T-1).\n",
    "    \"\"\"\n",
    "    def __init__(self, T=30, min_alpha=0.1, max_alpha=0.7, k=12.0):\n",
    "        self.T = T\n",
    "        self.alphas = []\n",
    "        for t in range(1, T+1):\n",
    "            # frac in [0..1]\n",
    "            frac = (t - 1) / (T - 1)  \n",
    "            # logistic\n",
    "            s = 1 / (1 + math.exp(-k * (frac - 0.5)))\n",
    "            alpha_t = min_alpha + (max_alpha - min_alpha) * s\n",
    "            self.alphas.append(alpha_t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.T\n",
    "\n",
    "    def __getitem__(self, t):\n",
    "        # t in [1..T], python indexing 0..T-1\n",
    "        return self.alphas[t - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 2) Forward noising that respects puzzle givens\n",
    "# ------------------------------------------------------------------------\n",
    "def forward_diffusion_with_puzzle(puzzle, solution, t, schedule, vocab_size, device):\n",
    "    \"\"\"\n",
    "    puzzle:   (batch, 81) with digits in [0..9]. 0 means blank, non-zero means given.\n",
    "    solution: (batch, 81) correct final solution\n",
    "    t:        an integer in [1..T]\n",
    "    schedule: contains alpha_t\n",
    "    returns x_t: partially noised solution (batch, 81)\n",
    "        - givens remain the same as solution's corresponding digit\n",
    "        - blank positions get replaced with random digits w.p. alpha_t\n",
    "    \"\"\"\n",
    "    alpha_t = schedule[t]  # fraction to noise\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Where puzzle is nonzero => givens => do NOT overwrite\n",
    "    givens_mask = (puzzle != 0)\n",
    "\n",
    "    # We'll noise only the positions that are blank in the puzzle\n",
    "    #   i.e. puzzle[i] == 0 => we can noise solution[i].\n",
    "    blank_mask = (puzzle == 0)\n",
    "\n",
    "    # Create random noise from [0..vocab_size-1] for the blank positions\n",
    "    noise = torch.randint(0, vocab_size, solution.shape, device=device)\n",
    "\n",
    "    # Decide which blank positions to replace with noise\n",
    "    replace_mask = (torch.rand_like(solution.float()) < alpha_t) & blank_mask\n",
    "\n",
    "    # x_t: start from the true solution, then replace with noise for some blank cells\n",
    "    x_t = solution.clone()\n",
    "    x_t[replace_mask] = noise[replace_mask]\n",
    "\n",
    "    # givens remain the same as the correct solution digit at that position\n",
    "    # (actually, this is already the default if puzzle != 0, but we do not overwrite them)\n",
    "    # so x_t[givens_mask] = solution[givens_mask] # if you want to be explicit\n",
    "\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 3) The model sees puzzle+partially noised solution as input\n",
    "# ------------------------------------------------------------------------\n",
    "class PuzzleDenoiser(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer that takes [puzzle || x_t] => shape (batch, 162) tokens\n",
    "    and outputs a distribution over solution tokens for the second half.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, puzzle, x_t):\n",
    "        \"\"\"\n",
    "        puzzle, x_t: (batch, 81)\n",
    "        We'll embed => shape (batch, 162, embed_dim)\n",
    "        Return shape => (batch, 162, vocab_size),\n",
    "        but we'll only evaluate the second half in the loss.\n",
    "        \"\"\"\n",
    "        batch_size = puzzle.size(0)\n",
    "        # Concatenate\n",
    "        inp = torch.cat([puzzle, x_t], dim=1)  # (batch, 162)\n",
    "        emb = self.embedding(inp)             # => (batch, 162, embed_dim)\n",
    "        enc_out = self.encoder(emb)           # => (batch, 162, embed_dim)\n",
    "        logits = self.output_layer(enc_out)   # => (batch, 162, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 4) Diffusion train step\n",
    "# ------------------------------------------------------------------------\n",
    "def diffusion_train_step(\n",
    "    model, \n",
    "    puzzle,      # (batch, 81)\n",
    "    solution,    # (batch, 81)\n",
    "    schedule,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Move to device\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    # Sample a random t\n",
    "    T = schedule.T\n",
    "    t = np.random.randint(1, T+1)\n",
    "\n",
    "    # Create x_t that doesn't overwrite puzzle givens\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    # Forward pass [puzzle || x_t]\n",
    "    logits = model(puzzle, x_t)  # shape (batch, 162, vocab_size)\n",
    "\n",
    "    # We only care about the second half (positions 81..161) \n",
    "    # for the solution. The first half is puzzle context.\n",
    "    logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "    # Compare to ground truth solution\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),\n",
    "        solution.reshape(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 5) Validation step\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def diffusion_eval_step(\n",
    "    model, \n",
    "    puzzle,\n",
    "    solution,\n",
    "    schedule,\n",
    "    loss_fn,\n",
    "    vocab_size,\n",
    "    device\n",
    "):\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    solution = solution.to(device)\n",
    "\n",
    "    t = np.random.randint(1, schedule.T+1)\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle, solution, t, schedule, vocab_size, device\n",
    "    )\n",
    "\n",
    "    logits = model(puzzle, x_t)\n",
    "    logits_solution_part = logits[:, 81:, :]  # only second half\n",
    "    loss = loss_fn(\n",
    "        logits_solution_part.reshape(-1, vocab_size),\n",
    "        solution.reshape(-1)\n",
    "    )\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 6) Iterative decoding to fill blank cells\n",
    "# ------------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def iterative_decode(\n",
    "    model,\n",
    "    puzzle,        # shape (batch, 81) puzzle givens\n",
    "    schedule,\n",
    "    vocab_size,\n",
    "    device,\n",
    "    steps=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Steps:\n",
    "      1) Start from x_T = fully noised in blank cells (or partial).\n",
    "      2) For t in [T..1], model predicts solution => we partially adopt it in blank cells\n",
    "         respecting puzzle givens.\n",
    "      3) Return final x_0\n",
    "    If steps=None => run the full T steps from schedule.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    puzzle = puzzle.to(device)\n",
    "    batch_size, seq_len = puzzle.shape\n",
    "    T = schedule.T if steps is None else steps\n",
    "\n",
    "    # Initialize x_t: fully noised in blank positions, puzzle givens remain correct solution digits \n",
    "    # (We don't have the solution during inference, so let's use puzzle for givens \n",
    "    #  and random for blanks)\n",
    "    x_t = puzzle.clone()\n",
    "    blank_mask = (puzzle == 0)\n",
    "    # fill blanks with random\n",
    "    x_t[blank_mask] = torch.randint(0, vocab_size, x_t[blank_mask].shape, device=device)\n",
    "\n",
    "    for t in range(T, 0, -1):\n",
    "        # forward pass\n",
    "        logits = model(puzzle, x_t)         # (batch, 162, vocab_size)\n",
    "        logits_solution_part = logits[:, 81:, :]  # (batch, 81, vocab_size)\n",
    "\n",
    "        # predicted solution tokens for second half\n",
    "        pred_sol = logits_solution_part.argmax(dim=-1)  # (batch, 81)\n",
    "\n",
    "        # Now adopt the model's predictions *only* in blank cells.\n",
    "        # Keep puzzle givens as-is. But if puzzle[i] was 0, we update from pred_sol.\n",
    "        x_t[blank_mask] = pred_sol[blank_mask]\n",
    "\n",
    "        # Optionally, you can do partial or probabilistic \"denoising\" \n",
    "        # (like in the paper). For simplicity, we do a 1-step \"take argmax\" each iteration.\n",
    "\n",
    "    return x_t  # hopefully a filled solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_sudoku_solve_rate(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val,    # (N, 81) puzzles\n",
    "    y_val,    # (N, 81) solutions\n",
    "    device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs iterative_decode on each puzzle in X_val,\n",
    "    checks how many are solved 100% correctly.\n",
    "    Returns a float in [0..1] for each batch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # If inputs are already batches, don't create new loader\n",
    "    if len(X_val.shape) == 2 and X_val.shape[0] <= batch_size:\n",
    "        puzzles = X_val.to(device)\n",
    "        solutions = y_val.to(device)\n",
    "        \n",
    "        x_filled = iterative_decode(\n",
    "            model=model,\n",
    "            puzzle=puzzles, \n",
    "            schedule=schedule,\n",
    "            vocab_size=vocab_size,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        eq_mask = (x_filled == solutions)\n",
    "        batch_solved = eq_mask.all(dim=1).sum()\n",
    "        solve_rate = batch_solved.item() / puzzles.size(0)\n",
    "        return solve_rate\n",
    "        \n",
    "    # For full dataset evaluation, use DataLoader\n",
    "    dataset = TensorDataset(X_val, y_val)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    solved_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for puzzles, solutions in tqdm(loader, desc=\"Evaluating Solve Rate\"):\n",
    "        puzzles = puzzles.to(device)\n",
    "        solutions = solutions.to(device)\n",
    "\n",
    "        x_filled = iterative_decode(\n",
    "            model=model,\n",
    "            puzzle=puzzles,\n",
    "            schedule=schedule,\n",
    "            vocab_size=vocab_size,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        eq_mask = (x_filled == solutions)\n",
    "        batch_solved = eq_mask.all(dim=1).sum()\n",
    "        solved_count += batch_solved.item()\n",
    "        total_count += puzzles.size(0)\n",
    "\n",
    "    solve_rate = solved_count / total_count\n",
    "    return solve_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def measure_token_accuracy(model, schedule, X_val, y_val, device, vocab_size=10, batch_size=32):\n",
    "    model.eval()\n",
    "    dataset = TensorDataset(X_val, y_val)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for puzzles, solutions in tqdm(loader, desc=\"Evaluating Token Accuracy\"):\n",
    "        puzzles = puzzles.to(device)\n",
    "        solutions = solutions.to(device)\n",
    "        x_filled = iterative_decode(model, puzzles, schedule, vocab_size, device)\n",
    "        correct += (x_filled == solutions).sum().item()\n",
    "        total += puzzles.numel()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# 7) Putting it all together: example training loop\n",
    "# ------------------------------------------------------------------------\n",
    "def train_puzzle_diffusion(\n",
    "    X_train, y_train, \n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=30,\n",
    "    embed_dim=256,\n",
    "    num_heads=8,\n",
    "    num_layers=4,\n",
    "    batch_size=32,\n",
    "    num_epochs=5\n",
    "):\n",
    "    \"\"\"\n",
    "    X_* are puzzle arrays of shape (N, 81).\n",
    "    y_* are solution arrays of shape (N, 81).\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    schedule = SigmoidDiffusionSchedule(\n",
    "        T=T, \n",
    "        min_alpha=0.1, \n",
    "        max_alpha=0.7,\n",
    "        k = 12.0\n",
    "    )\n",
    "\n",
    "    model = PuzzleDenoiser(\n",
    "        vocab_size=vocab_size, \n",
    "        embed_dim=embed_dim, \n",
    "        num_heads=num_heads, \n",
    "        num_layers=num_layers\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setup data loaders\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    val_dataset   = TensorDataset(X_val,   y_val)\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader    = DataLoader(val_dataset,   batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch_puzzle, batch_solution in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "            loss_val = diffusion_train_step(\n",
    "                model=model,\n",
    "                puzzle=batch_puzzle,\n",
    "                solution=batch_solution,\n",
    "                schedule=schedule,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                vocab_size=vocab_size,\n",
    "                device=device\n",
    "            )\n",
    "            train_losses.append(loss_val)\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_losses = []\n",
    "        \n",
    "        # Calculate accuracy on full validation set once per epoch\n",
    "        val_accuracy = measure_sudoku_solve_rate(\n",
    "            model,\n",
    "            schedule,\n",
    "            X_val,\n",
    "            y_val,\n",
    "            device=device,\n",
    "            vocab_size=vocab_size,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        token_accuracy = measure_token_accuracy(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            X_val=X_val,\n",
    "            y_val=y_val,\n",
    "            device=device,\n",
    "            vocab_size=vocab_size,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_puzzle, batch_solution in tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val  ]\"):\n",
    "                # Get validation loss\n",
    "                vloss = diffusion_eval_step(\n",
    "                    model=model,\n",
    "                    puzzle=batch_puzzle,\n",
    "                    solution=batch_solution, \n",
    "                    schedule=schedule,\n",
    "                    loss_fn=loss_fn,\n",
    "                    vocab_size=vocab_size,\n",
    "                    device=device\n",
    "                )\n",
    "                val_losses.append(vloss)\n",
    "                \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}\")\n",
    "        print(f\"Solve rate on validation set: {val_accuracy*100:.2f}%\")\n",
    "        print(f\"Token-level accuracy on validation set: {token_accuracy*100:.2f}%\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"puzzle_diffuser_best.pt\")\n",
    "            print(f\"  [*] Best model saved @ val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return model, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load sudoku data\n",
    "df = pd.read_csv('./data/sudoku.csv')\n",
    "\n",
    "# Convert strings to tensors\n",
    "def preprocess_sudoku(puzzle_str):\n",
    "    # Convert string to list of integers and then to tensor\n",
    "    return torch.tensor([int(d) for d in puzzle_str], dtype=torch.long)\n",
    "\n",
    "# Convert all puzzles and solutions\n",
    "puzzles = torch.stack([preprocess_sudoku(p) for p in df['quizzes']])\n",
    "solutions = torch.stack([preprocess_sudoku(s) for s in df['solutions']])\n",
    "\n",
    "# Karpathy split (90/5/5)\n",
    "train_size = 0.9\n",
    "val_size = 0.05\n",
    "test_size = 0.05\n",
    "\n",
    "# First split into train and temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    puzzles, solutions, train_size=train_size, random_state=42\n",
    ")\n",
    "\n",
    "# Split temp into val and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:   1%|▏         | 210/14063 [00:56<1:02:40,  3.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, schedule \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_puzzle_diffusion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 51\u001b[0m, in \u001b[0;36mtrain_puzzle_diffusion\u001b[1;34m(X_train, y_train, X_val, y_val, vocab_size, T, embed_dim, num_heads, num_layers, batch_size, num_epochs)\u001b[0m\n\u001b[0;32m     49\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_puzzle, batch_solution \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_train_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpuzzle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_puzzle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_solution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschedule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss_val)\n\u001b[0;32m     62\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_losses)\n",
      "Cell \u001b[1;32mIn[7], line 42\u001b[0m, in \u001b[0;36mdiffusion_train_step\u001b[1;34m(model, puzzle, solution, schedule, optimizer, loss_fn, vocab_size, device)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Compare to ground truth solution\u001b[39;00m\n\u001b[0;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(\n\u001b[0;32m     39\u001b[0m     logits_solution_part\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size),\n\u001b[0;32m     40\u001b[0m     solution\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, schedule = train_puzzle_diffusion(\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    vocab_size=10,\n",
    "    T=40,\n",
    "    embed_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=8,\n",
    "    batch_size=64,\n",
    "    num_epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle: tensor([[0, 4, 2, 0, 0, 9, 0, 7, 5, 9, 0, 0, 0, 0, 7, 0, 0, 3, 3, 0, 5, 6, 1, 0,\n",
      "         9, 0, 0, 0, 0, 4, 9, 7, 8, 0, 0, 6, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 8,\n",
      "         4, 0, 6, 2, 0, 0, 0, 6, 7, 0, 0, 0, 4, 3, 8, 8, 0, 0, 7, 0, 0, 0, 9, 2,\n",
      "         0, 0, 0, 0, 5, 0, 0, 0, 0]])\n",
      "Solution: tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]])\n",
      "x_1 (alpha=0.101) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 4, 1, 8,\n",
      "         4, 1, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 9, 4, 5, 9, 2,\n",
      "         4, 9, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_2 (alpha=0.102) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 2, 4, 4, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_3 (alpha=0.103) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 6, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 9, 6, 6, 9, 3, 9, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 4]], device='cuda:0')\n",
      "x_4 (alpha=0.105) = tensor([[1, 4, 2, 3, 1, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 0, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 9, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 6, 7, 6, 1]], device='cuda:0')\n",
      "x_5 (alpha=0.108) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 0, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 7, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 8, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_6 (alpha=0.112) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 2, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 7, 9, 3, 1, 5, 5, 5, 5, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 1, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_7 (alpha=0.117) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 7, 5, 2, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 4, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         6, 2, 9, 8, 5, 6, 7, 6, 4]], device='cuda:0')\n",
      "x_8 (alpha=0.126) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 5, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 5, 6, 6, 9, 3, 2, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 1, 1, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_9 (alpha=0.138) = tensor([[1, 4, 2, 3, 0, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 4, 5, 4, 9, 7, 8, 1, 1, 6, 6, 9, 3, 1, 2, 5, 8, 8, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 1, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         7, 2, 5, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_10 (alpha=0.156) = tensor([[1, 4, 2, 3, 8, 9, 8, 7, 5, 9, 8, 7, 5, 4, 7, 1, 7, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 6, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 5, 6, 7, 2, 9, 1, 4, 3, 8, 8, 3, 9, 7, 1, 4, 5, 9, 2,\n",
      "         4, 7, 9, 8, 5, 3, 7, 6, 1]], device='cuda:0')\n",
      "x_11 (alpha=0.181) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 3, 6, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 6, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 8, 5, 8, 4, 7, 2, 1, 8,\n",
      "         4, 3, 6, 2, 5, 6, 9, 6, 7, 2, 9, 8, 4, 3, 8, 8, 3, 2, 7, 5, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 2, 1]], device='cuda:0')\n",
      "x_12 (alpha=0.214) = tensor([[1, 4, 2, 3, 8, 9, 5, 7, 5, 9, 8, 6, 5, 3, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 8, 6, 7, 2, 9, 1, 4, 3, 8, 8, 8, 1, 7, 6, 4, 5, 9, 2,\n",
      "         4, 6, 7, 8, 5, 9, 7, 6, 1]], device='cuda:0')\n",
      "x_13 (alpha=0.257) = tensor([[1, 4, 2, 3, 2, 9, 6, 7, 5, 9, 8, 1, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 5, 4, 7, 1, 4, 9, 7, 8, 3, 1, 6, 6, 0, 3, 6, 6, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 4, 2, 6, 7, 8, 9, 1, 4, 3, 8, 8, 3, 1, 7, 5, 5, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 4, 7, 6, 1]], device='cuda:0')\n",
      "x_14 (alpha=0.310) = tensor([[1, 4, 2, 8, 3, 9, 6, 7, 5, 9, 8, 3, 5, 4, 7, 1, 6, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 4, 4, 5, 4, 9, 7, 8, 3, 1, 6, 6, 9, 3, 1, 2, 8, 8, 4, 9, 2, 1, 8,\n",
      "         4, 8, 6, 2, 5, 9, 6, 6, 7, 2, 6, 2, 4, 3, 8, 8, 3, 8, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 8, 5, 3, 7, 8, 1]], device='cuda:0')\n",
      "x_15 (alpha=0.369) = tensor([[1, 4, 2, 3, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 4, 2, 3, 3, 7, 5, 6, 1, 9,\n",
      "         9, 0, 4, 2, 9, 4, 9, 7, 8, 3, 1, 6, 6, 3, 3, 1, 8, 5, 8, 4, 7, 7, 1, 8,\n",
      "         4, 8, 6, 2, 5, 9, 5, 6, 7, 5, 9, 8, 4, 3, 8, 8, 4, 6, 7, 6, 0, 5, 9, 2,\n",
      "         4, 1, 9, 0, 5, 3, 4, 6, 1]], device='cuda:0')\n",
      "x_16 (alpha=0.431) = tensor([[6, 4, 2, 3, 8, 9, 9, 7, 5, 9, 8, 4, 5, 4, 7, 1, 0, 3, 3, 2, 5, 6, 1, 2,\n",
      "         9, 8, 4, 2, 2, 4, 9, 7, 8, 4, 1, 6, 6, 9, 3, 1, 2, 5, 8, 1, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 5, 6, 7, 5, 9, 9, 4, 3, 8, 8, 3, 2, 7, 6, 5, 5, 9, 2,\n",
      "         1, 2, 5, 8, 5, 3, 9, 4, 8]], device='cuda:0')\n",
      "x_17 (alpha=0.490) = tensor([[1, 4, 2, 9, 8, 9, 6, 7, 5, 9, 8, 6, 7, 1, 7, 2, 2, 3, 3, 0, 5, 6, 1, 2,\n",
      "         9, 8, 4, 1, 5, 4, 9, 7, 8, 3, 5, 6, 6, 9, 3, 1, 2, 5, 2, 4, 6, 5, 1, 8,\n",
      "         4, 3, 6, 2, 8, 6, 3, 6, 7, 3, 9, 0, 4, 3, 8, 8, 3, 8, 7, 8, 4, 0, 9, 2,\n",
      "         9, 2, 9, 2, 5, 0, 8, 6, 8]], device='cuda:0')\n",
      "x_18 (alpha=0.543) = tensor([[3, 4, 2, 1, 8, 9, 6, 7, 5, 9, 2, 4, 5, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 6,\n",
      "         9, 5, 3, 2, 5, 4, 9, 7, 8, 8, 1, 6, 2, 0, 3, 2, 9, 5, 8, 4, 9, 7, 1, 8,\n",
      "         4, 3, 6, 2, 5, 8, 5, 6, 7, 2, 2, 7, 4, 3, 8, 8, 5, 2, 7, 6, 4, 5, 9, 2,\n",
      "         4, 2, 9, 1, 5, 3, 7, 4, 0]], device='cuda:0')\n",
      "x_19 (alpha=0.586) = tensor([[1, 4, 2, 5, 8, 9, 7, 7, 5, 9, 8, 7, 7, 4, 7, 4, 9, 3, 3, 7, 5, 6, 1, 6,\n",
      "         9, 8, 7, 2, 0, 4, 9, 7, 8, 2, 4, 6, 4, 9, 3, 7, 3, 5, 7, 1, 0, 4, 1, 8,\n",
      "         4, 3, 6, 2, 5, 9, 0, 6, 7, 2, 4, 1, 4, 3, 8, 8, 3, 1, 7, 6, 4, 5, 9, 2,\n",
      "         5, 2, 4, 5, 5, 3, 1, 6, 6]], device='cuda:0')\n",
      "x_20 (alpha=0.619) = tensor([[6, 4, 2, 5, 8, 9, 6, 7, 5, 9, 7, 6, 1, 7, 7, 6, 7, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 1, 9, 2, 5, 4, 9, 7, 8, 3, 1, 6, 1, 9, 3, 1, 4, 2, 7, 7, 7, 7, 1, 8,\n",
      "         4, 5, 6, 2, 1, 9, 5, 6, 7, 2, 7, 1, 4, 3, 8, 8, 3, 0, 7, 6, 8, 5, 9, 2,\n",
      "         3, 2, 9, 4, 5, 3, 7, 4, 9]], device='cuda:0')\n",
      "x_21 (alpha=0.644) = tensor([[0, 4, 2, 1, 7, 9, 1, 7, 5, 9, 1, 6, 5, 5, 7, 1, 3, 3, 3, 2, 5, 6, 1, 7,\n",
      "         9, 9, 7, 2, 8, 4, 9, 7, 8, 3, 1, 6, 8, 7, 3, 9, 1, 0, 8, 9, 7, 5, 1, 8,\n",
      "         4, 8, 6, 2, 0, 9, 5, 6, 7, 6, 9, 2, 4, 3, 8, 8, 6, 7, 7, 6, 7, 6, 9, 2,\n",
      "         4, 2, 7, 8, 5, 2, 7, 6, 4]], device='cuda:0')\n",
      "x_22 (alpha=0.662) = tensor([[1, 4, 2, 6, 8, 9, 9, 7, 5, 9, 3, 2, 7, 7, 7, 9, 4, 3, 3, 7, 5, 6, 1, 4,\n",
      "         9, 8, 7, 4, 8, 4, 9, 7, 8, 1, 5, 6, 6, 9, 3, 1, 2, 2, 4, 7, 7, 9, 1, 8,\n",
      "         4, 4, 6, 2, 5, 9, 0, 6, 7, 6, 6, 1, 4, 3, 8, 8, 5, 1, 7, 8, 7, 5, 9, 2,\n",
      "         4, 4, 9, 8, 5, 1, 3, 4, 5]], device='cuda:0')\n",
      "x_23 (alpha=0.674) = tensor([[8, 4, 2, 5, 9, 9, 3, 7, 5, 9, 0, 1, 3, 4, 7, 5, 4, 3, 3, 7, 5, 6, 1, 1,\n",
      "         9, 2, 5, 8, 5, 4, 9, 7, 8, 3, 2, 6, 2, 9, 3, 4, 2, 5, 4, 3, 7, 1, 1, 8,\n",
      "         4, 7, 6, 2, 5, 5, 0, 6, 7, 6, 9, 7, 4, 3, 8, 8, 6, 9, 7, 8, 0, 8, 9, 2,\n",
      "         1, 2, 7, 8, 5, 8, 7, 6, 0]], device='cuda:0')\n",
      "x_24 (alpha=0.683) = tensor([[1, 4, 2, 9, 0, 9, 4, 7, 5, 9, 8, 8, 5, 8, 7, 7, 6, 3, 3, 1, 5, 6, 1, 2,\n",
      "         9, 9, 0, 7, 3, 4, 9, 7, 8, 0, 0, 6, 8, 5, 3, 1, 2, 6, 8, 3, 7, 9, 1, 8,\n",
      "         4, 7, 6, 2, 5, 1, 5, 6, 7, 8, 9, 1, 4, 3, 8, 8, 3, 1, 7, 6, 7, 5, 9, 2,\n",
      "         4, 0, 9, 8, 5, 3, 2, 5, 2]], device='cuda:0')\n",
      "x_25 (alpha=0.688) = tensor([[5, 4, 2, 4, 8, 9, 6, 7, 5, 9, 5, 7, 2, 4, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 8, 2, 2, 3, 4, 9, 7, 8, 3, 1, 6, 6, 4, 3, 1, 4, 5, 9, 4, 7, 2, 1, 8,\n",
      "         4, 8, 6, 2, 9, 6, 5, 6, 7, 2, 1, 1, 4, 3, 8, 8, 4, 0, 7, 4, 6, 0, 9, 2,\n",
      "         4, 4, 9, 1, 5, 6, 7, 6, 5]], device='cuda:0')\n",
      "x_26 (alpha=0.692) = tensor([[1, 4, 2, 1, 8, 9, 6, 7, 5, 9, 8, 6, 5, 4, 7, 1, 2, 3, 3, 4, 5, 6, 1, 7,\n",
      "         9, 1, 8, 0, 8, 4, 9, 7, 8, 3, 1, 6, 3, 6, 3, 6, 0, 4, 7, 4, 8, 4, 1, 8,\n",
      "         4, 9, 6, 2, 6, 4, 5, 6, 7, 2, 2, 4, 4, 3, 8, 8, 0, 9, 7, 6, 4, 5, 9, 2,\n",
      "         9, 8, 1, 4, 5, 6, 7, 6, 3]], device='cuda:0')\n",
      "x_27 (alpha=0.695) = tensor([[3, 4, 2, 1, 8, 9, 8, 7, 5, 9, 4, 6, 8, 1, 7, 0, 2, 3, 3, 0, 5, 6, 1, 5,\n",
      "         9, 8, 4, 2, 4, 4, 9, 7, 8, 7, 1, 6, 9, 4, 3, 7, 0, 9, 6, 4, 8, 3, 1, 8,\n",
      "         4, 3, 6, 2, 2, 1, 2, 6, 7, 4, 6, 1, 4, 3, 8, 8, 3, 1, 7, 6, 8, 5, 9, 2,\n",
      "         4, 7, 8, 6, 5, 9, 9, 6, 5]], device='cuda:0')\n",
      "x_28 (alpha=0.697) = tensor([[1, 4, 2, 2, 6, 9, 6, 7, 5, 9, 4, 6, 7, 1, 7, 1, 2, 3, 3, 7, 5, 6, 1, 2,\n",
      "         9, 3, 9, 6, 3, 4, 9, 7, 8, 6, 7, 6, 9, 0, 3, 1, 6, 9, 8, 4, 8, 4, 1, 8,\n",
      "         4, 2, 6, 2, 6, 3, 1, 6, 7, 2, 5, 4, 4, 3, 8, 8, 2, 2, 7, 8, 4, 4, 9, 2,\n",
      "         0, 2, 7, 8, 5, 3, 1, 6, 6]], device='cuda:0')\n",
      "x_29 (alpha=0.698) = tensor([[1, 4, 2, 0, 8, 9, 9, 7, 5, 9, 8, 9, 1, 1, 7, 1, 0, 3, 3, 9, 5, 6, 1, 7,\n",
      "         9, 7, 7, 2, 5, 4, 9, 7, 8, 2, 3, 6, 6, 5, 3, 7, 2, 8, 7, 4, 7, 7, 1, 8,\n",
      "         4, 3, 6, 2, 3, 1, 8, 6, 7, 6, 4, 9, 4, 3, 8, 8, 3, 1, 7, 6, 0, 3, 9, 2,\n",
      "         6, 2, 9, 3, 5, 0, 0, 6, 1]], device='cuda:0')\n",
      "x_30 (alpha=0.699) = tensor([[5, 4, 2, 1, 7, 9, 5, 7, 5, 9, 8, 3, 5, 7, 7, 1, 2, 3, 3, 7, 5, 6, 1, 9,\n",
      "         9, 4, 5, 2, 3, 4, 9, 7, 8, 5, 1, 6, 6, 9, 3, 1, 2, 1, 4, 4, 7, 3, 1, 8,\n",
      "         4, 3, 6, 2, 4, 9, 0, 6, 7, 2, 3, 3, 4, 3, 8, 8, 5, 8, 7, 2, 4, 5, 9, 2,\n",
      "         4, 5, 0, 4, 5, 4, 7, 1, 1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# 2) CREATE THE NEW SCHEDULE\n",
    "#############################################\n",
    "schedule = SigmoidDiffusionSchedule(\n",
    "    T=30,\n",
    "    min_alpha=0.1,\n",
    "    max_alpha=0.7,\n",
    "    k=12.0\n",
    ")\n",
    "\n",
    "#############################################\n",
    "# 3) PICK A SAMPLE PUZZLE & SOLUTION\n",
    "#############################################\n",
    "sample_puzzle = X_train[0:1]\n",
    "sample_solution = y_train[0:1]\n",
    "\n",
    "print(\"Puzzle:\", sample_puzzle)\n",
    "print(\"Solution:\", sample_solution)\n",
    "\n",
    "#############################################\n",
    "# 4) SHOW x_1, x_2, ... x_T\n",
    "#############################################\n",
    "vocab_size = 10  # digits 0-9\n",
    "for t in range(1, schedule.T+1):\n",
    "    alpha_t = schedule[t]  # just to see the noise fraction\n",
    "    x_t = forward_diffusion_with_puzzle(\n",
    "        puzzle=sample_puzzle, \n",
    "        solution=sample_solution, \n",
    "        t=t, \n",
    "        schedule=schedule, \n",
    "        vocab_size=vocab_size, \n",
    "        device=device\n",
    "    )\n",
    "    print(f\"x_{t} (alpha={alpha_t:.3f}) =\", x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Then to do iterative decoding:\n",
    "puzzle_batch = X_val[0:2]  # for example\n",
    "x_filled = iterative_decode(\n",
    "    model, \n",
    "    puzzle=puzzle_batch, \n",
    "    schedule=schedule, \n",
    "    vocab_size=10,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")\n",
    "print(\"Puzzle: \", puzzle_batch)\n",
    "print(\"Decoded solution: \", x_filled)\n",
    "print(\"Original solution: \", y_val[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Solve Rate: 100%|██████████| 4/4 [00:00<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve rate on validation set: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = measure_sudoku_solve_rate(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val[0:100],\n",
    "    y_val[0:100],\n",
    "    device=device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Solve rate on validation set: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Token Accuracy: 100%|██████████| 4/4 [00:01<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token-level accuracy on validation set: 48.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "token_accuracy = measure_token_accuracy(\n",
    "    model,\n",
    "    schedule,\n",
    "    X_val[0:100],\n",
    "    y_val[0:100],\n",
    "    device=device,\n",
    "    vocab_size=10,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Token-level accuracy on validation set: {token_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
